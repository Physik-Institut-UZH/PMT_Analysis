<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>pmt_analysis.utils.input API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pmt_analysis.utils.input</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import numpy as np
import pandas as pd
import uproot
import concurrent.futures
import os
import glob
import warnings
from typing import Optional, Union


class ADCRawData:
    &#34;&#34;&#34;General class to import the analog-to-digital converter (ADC) raw data.

    Attributes:
        verbose: Verbosity of output.
        raw_input_path: Path with the ROOT files to be imported.
        raw_input_fileslist: Array of ROOT files to be imported.
        adc_f: ADC sampling frequency in samples per second.
        adc_r: ADC resolution in volts per bin.
        adc_z: ADC input impedance.
        adc_a: Amplification factor of readout.
        elementary_charge: Electron charge in C.
        adc_area_to_e: Conversion factor pulse area in ADC units to charge in units of elementary charge.
    &#34;&#34;&#34;

    def __init__(self, raw_input_path: str, raw_input_filepattern: str = &#39;*.root&#39;,
                 adc_type: str = &#39;v1730d&#39;, verbose: bool = False):
        &#34;&#34;&#34;Init of the ADCRawData class.

        Defines the list of files to be loaded and global parameters from the data acquisition.

        Args:
            raw_input_path: Path with the ROOT files to be imported.
            raw_input_filepattern: Name of file or pattern of files to be imported. Default: `*root` for
                all ROOT files in `raw_input_path`.
            adc_type: ADC model used for the data acquisition. Options: `v1724`, `v1730d` (default).
            verbose: Set verbose output.
        &#34;&#34;&#34;
        self.verbose = verbose
        self.raw_input_path = raw_input_path
        self.raw_input_fileslist = glob.glob(os.path.join(raw_input_path, raw_input_filepattern))
        if len(self.raw_input_fileslist) == 0:
            raise ValueError(&#39;No files found to be loaded. Provide valid path and filename pattern.&#39;)
        elif &#39;.root&#39; not in &#39; &#39;.join(self.raw_input_fileslist):
            raise TypeError(&#39;There seem to be no .root files among the selected files.&#39;)
        elif self.verbose:
            print(&#39;Selected following files to be loaded:&#39;)
            print(*[el.split(os.sep)[-1] for el in self.raw_input_fileslist], sep=&#34;\n&#34;)
        # Define conversion factors depending on ADC type
        self.get_conversion_factors(adc_type)

    def get_conversion_factors(self, adc_type: str):
        &#34;&#34;&#34;Define global conversion factors depending on ADC type.

        Args:
            adc_type: ADC model used for the data acquisition. Options: `v1724`, `v1730d`.
        &#34;&#34;&#34;
        self.elementary_charge = 1.60218e-19  # electron charge
        if str(adc_type).lower() in [&#39;v1730d&#39;, &#39;v1730&#39;, &#39;1730&#39;, &#39;1730d&#39;]:  # CAEN V1730D
            self.adc_f = 500e6  # ADC sampling frequency: 500 MS/s digitization speed (2 ns bins)
            self.adc_r = 2.0 / 2 ** 14  # ADC resolution in volts per bin: 14 bit ADC, 2V voltage range
            self.adc_z = 50  # input impedance: 50 Ohm termination to ground
            self.adc_a = 10  # amplification factor: 10 times gain into 50 Ohm impedance
        elif str(adc_type).lower() in [&#39;v1724&#39;, &#39;1724&#39;]:  # CAEN V1730D
            self.adc_f = 100e6  # ADC sampling frequency: 100 MS/s digitization speed (10 ns bins)
            self.adc_r = 2.25 / 2 ** 14  # ADC resolution in volts per bin: 14 bit ADC, 2.25V voltage range
            self.adc_z = 50  # input impedance: 50 Ohm termination to ground
            self.adc_a = 10  # amplification factor: 10 times gain into 50 Ohm impedance
        else:
            raise ValueError(
                &#39;{} is no valid option for `adc_type`. Select from (`v1724`, `v1730d`).&#39;.format(adc_type))
        # Conversion factor pulse area in ADC units to charge in units of elementary charge.
        self.adc_area_to_e = self.adc_r / (self.adc_f * self.adc_z * self.adc_a * self.elementary_charge)

    def set_run_conditions(self):
        &#34;&#34;&#34;Define the run specific conditions.
        TODO: fill, extract info from raw_input_path
        &#34;&#34;&#34;
        pass

    def get_trees(self) -&gt; str:
        &#34;&#34;&#34;Find name of unique available tree in ROOT files to be loaded.

        Returns:
            tree: Unique ROOT tree name.
        &#34;&#34;&#34;
        # Iterate over selected files.
        for i, input_file in enumerate(self.raw_input_fileslist):
            with uproot.open(input_file) as file:
                # Get tree names in file.
                trees_file = file.keys()
                if len(trees_file) == 0:
                    raise ValueError(&#39;No trees found in selected ROOT file {}.&#39;.format(input_file))
                # Convert tree names to string.
                trees_file = [el for el in trees_file]
                # For large data sets, ROOT may generate additional copies of a
                # particular tree, consequently named e.g. `t1;1`, `t1;2`,...
                # We only want the name before the semicolon.
                trees_file = np.unique([el.split(&#39;;&#39;)[0] for el in trees_file])
            # Concatenate with previous iterations.
            if i != 0:
                trees = np.unique(np.concatenate([trees, trees_file], axis=0))
            else:
                trees = trees_file
        # Require and return only one unique tree name.
        if len(trees) &gt; 1:
            raise ValueError(&#39;Multiple ({}) trees found in selected ROOT file.&#39;
                             &#39;Specify single tree to be loaded.&#39;.format(len(trees)))
        else:
            tree = str(trees[0])
        return tree

    def get_branches(self, tree: Optional[str] = None) -&gt; np.ndarray:
        &#34;&#34;&#34;Find branch names in ROOT files to be loaded.

        Args:
            tree: Name of the ROOT tree to be inspected. If `None` deduce with
                `pmt_analysis.utils.input.ADCRawData.get_trees` method.

        Returns:
            branches: Array with branch names in selected ROOT files.
        &#34;&#34;&#34;
        # Define tree to be inspected.
        if tree is None:
            tree = self.get_trees()
        else:
            if type(tree) != str:
                raise TypeError(&#39;Parameter `tree` must be of type `str`.&#39;)
        # Iterate over selected files.
        for i, input_file in enumerate(self.raw_input_fileslist):
            with uproot.open(input_file) as file:
                # Get branch names in given tree.
                branches_file = file[tree].keys()
                if len(branches_file) == 0:
                    raise ValueError(&#39;No branches found for tree {} in selected ROOT file {}.&#39;.format(tree, input_file))
                # Convert branch names to string.
                branches_file = np.array([el for el in branches_file])
            # Concatenate with previous iterations.
            if i != 0:
                branches = np.unique(np.concatenate([branches, branches_file], axis=0))
            else:
                branches = branches_file
        return branches

    def get_branch_data(self, branch: Union[str, int], tree: Optional[str] = None) -&gt; np.ndarray:
        &#34;&#34;&#34;Retrieve data of specified branch and tree in all selected ROOT files.

        Args:
            branch: Branch of ROOT file to be loaded. Also allows for input of an ADC channel number (int).
            tree: ROOT tree to load. If `None` deduce with `pmt_analysis.utils.input.ADCRawData.get_trees` method.
        Returns:
            out: Array with data of selected branch. Typically, Unix timestamp for `branch = &#39;Time&#39;` or
                ADC data of selected channel, e.g. waveforms of channel 0 for `branch = &#39;wf0&#39;` or `branch = 0`.
        &#34;&#34;&#34;
        # Define tree to be inspected.
        if tree is None:
            tree = self.get_trees()
        else:
            if type(tree) != str:
                raise TypeError(&#39;Parameter `tree` must be of type `str`.&#39;)
        # Make optional to pass channel number (int) for branch.
        if type(branch) == int:
            branch = &#39;wf{}&#39;.format(branch)
        if type(branch) != str:
            raise TypeError(&#39;Parameter `branch` must be of type `str` or `int`.&#39;)
        # Check availability of selected branch.
        if branch not in self.get_branches(tree):
            raise ValueError(&#39;Branch {} not found in tree {} of selected ROOT files.&#39;.format(branch, tree))
        # Iteratively load data from ROOT files.
        executor = concurrent.futures.ThreadPoolExecutor(8)
        out = uproot.concatenate(files={el: tree for el in self.raw_input_fileslist},
                                 expressions=branch,
                                 library=&#39;np&#39;,
                                 step_size=100000,
                                 allow_missing=True,
                                 decompression_executor=executor,
                                 interpretation_executor=executor
                                 )[branch]
        return out


class ScalerRawData:
    &#34;&#34;&#34;General class to import the CAEN V260 scaler raw data from space-separated `.dat` files.

    Attributes:
        verbose: Verbosity of output.
        trim_empty: Remove columns for non-active channels.
        files: List of full file path and name of all `.dat` files to be loaded.
        t_int: Data acquisition interval in seconds.
    &#34;&#34;&#34;

    def __init__(self, files: Union[str, list], trim_empty: bool = True, verbose: bool = True):
        &#34;&#34;&#34;Init of the ScalerRawData class.

        Defines the list of files to be loaded and global parameters from the data acquisition.

        Args:
            files: Files to be loaded. Possible formats: 
                String of full file path and name for a single file to be loaded; 
                list of strings of full file paths and names for multiple files to be loaded; 
                string of full file path for the parent directory of all `.dat` files to be loaded.
            trim_empty: Remove columns for non-active channels.
            verbose: Verbosity of output.
        &#34;&#34;&#34;
        self.verbose = verbose
        self.trim_empty = trim_empty
        self.files = self.convert_input_path(input_str_or_list=files)
        if verbose:
            print(&#39;Files to be loaded:&#39;)
            print(*self.files, sep=&#34;\n&#34;)
        self.t_int = self.get_t_int()
        if verbose:
            print(&#39;Data acquisition interval: {} s&#39;.format(self.t_int))

    @staticmethod
    def convert_input_path(input_str_or_list: Union[str, list]) -&gt; list:
        &#34;&#34;&#34;Convert `input` parameter to appropriate format, 
        i.e. list of strings indicating full file paths and names.

        Args:
            input_str_or_list: Files to be loaded. Possible formats:
                String of full file path and name for a single file to be loaded;
                list of strings of full file paths and names for multiple files to be loaded;
                string of full file path for the parent directory of all `.dat` files to be loaded.
        &#34;&#34;&#34;
        # Construct list of strings with paths and names of files to be loaded.
        if type(input_str_or_list) == str:
            if os.path.isfile(input_str_or_list):
                output_list = [input_str_or_list]  # single file name to list
            elif os.path.isdir(input_str_or_list):
                output_list = glob.glob(os.path.join(input_str_or_list, &#39;*.dat&#39;))  # find all .dat files in directory
                if len(output_list) &lt; 1:
                    raise ValueError(&#39;No files found to be loaded.&#39;)
            else:
                raise ValueError(&#39;Cannot access {}: No such file or directory&#39;.format(input_str_or_list))
        elif type(input_str_or_list) != list:
            raise TypeError(&#39;Values for file parameter must be of type str or list, &#39;
                            &#39;but is of type {}.&#39;.format(type(input_str_or_list)))
        else:
            output_list = input_str_or_list

        # Remove possible file names not in .dat format.
        if np.any(~np.array([&#39;.dat&#39; in el for el in output_list])):
            warnings.warn(&#39;Removing files not in .dat format.&#39;)
            output_list = [el for el in output_list if &#39;.dat&#39; in el]
            if len(output_list) &lt; 1:
                raise ValueError(&#39;No files found to be loaded.&#39;)

        return output_list

    def get_t_int(self) -&gt; int:
        &#34;&#34;&#34;Get data acquisition interval and ensure that all files have the same acquisition interval.

        Returns:
            t_int: Data acquisition interval in seconds.
        &#34;&#34;&#34;
        # Obtain acquisition intervals from files to be loaded.
        t_int_list = []
        for file in self.files:
            with open(file) as f:
                first_line = f.readline().strip(&#39;\n&#39;).split(&#39; &#39;)
                t_int_list.append(int(first_line[first_line.index(&#39;Interval:&#39;) + 1]))
        # Ensure that all files have the same acquisition interval.
        if np.unique(t_int_list).shape[0] == 1:
            t_int = t_int_list[0]
        else:
            raise ValueError(&#39;Loaded files have different acquisition intervals.&#39;)

        return t_int

    def get_data(self) -&gt; pd.DataFrame:
        &#34;&#34;&#34;Load scaler data.

        Returns:
            df: Pandas data frame with scaler data. Contains timestamps, datetimes, as well as counts (`ch*_cnts`)
                and count rates (`ch*_freq`) in the respective data acquisition intervals for the individual channels.
        &#34;&#34;&#34;
        scaler_column_names = np.concatenate([np.array([&#39;timestamp&#39;]),
                                              np.array([[&#39;ch{}_cnts&#39;.format(i), &#39;ch{}_freq&#39;.format(i)]
                                                        for i in range(16)]).flatten()])
        df_list = (pd.read_csv(file, sep=&#39;\s+&#39;, lineterminator=&#39;\n&#39;, skiprows=1,
                               header=None, names=scaler_column_names) for file in self.files)
        df = pd.concat(df_list, ignore_index=True)

        # Remove columns with no counts
        if self.trim_empty:
            df.drop(df.columns[df.mean(axis=0) &lt; 1e-3], axis=1, inplace=True)

        return df</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pmt_analysis.utils.input.ADCRawData"><code class="flex name class">
<span>class <span class="ident">ADCRawData</span></span>
<span>(</span><span>raw_input_path: str, raw_input_filepattern: str = '*.root', adc_type: str = 'v1730d', verbose: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>General class to import the analog-to-digital converter (ADC) raw data.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>verbose</code></strong></dt>
<dd>Verbosity of output.</dd>
<dt><strong><code>raw_input_path</code></strong></dt>
<dd>Path with the ROOT files to be imported.</dd>
<dt><strong><code>raw_input_fileslist</code></strong></dt>
<dd>Array of ROOT files to be imported.</dd>
<dt><strong><code>adc_f</code></strong></dt>
<dd>ADC sampling frequency in samples per second.</dd>
<dt><strong><code>adc_r</code></strong></dt>
<dd>ADC resolution in volts per bin.</dd>
<dt><strong><code>adc_z</code></strong></dt>
<dd>ADC input impedance.</dd>
<dt><strong><code>adc_a</code></strong></dt>
<dd>Amplification factor of readout.</dd>
<dt><strong><code>elementary_charge</code></strong></dt>
<dd>Electron charge in C.</dd>
<dt><strong><code>adc_area_to_e</code></strong></dt>
<dd>Conversion factor pulse area in ADC units to charge in units of elementary charge.</dd>
</dl>
<p>Init of the ADCRawData class.</p>
<p>Defines the list of files to be loaded and global parameters from the data acquisition.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>raw_input_path</code></strong></dt>
<dd>Path with the ROOT files to be imported.</dd>
<dt><strong><code>raw_input_filepattern</code></strong></dt>
<dd>Name of file or pattern of files to be imported. Default: <code>*root</code> for
all ROOT files in <code>raw_input_path</code>.</dd>
<dt><strong><code>adc_type</code></strong></dt>
<dd>ADC model used for the data acquisition. Options: <code>v1724</code>, <code>v1730d</code> (default).</dd>
<dt><strong><code>verbose</code></strong></dt>
<dd>Set verbose output.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ADCRawData:
    &#34;&#34;&#34;General class to import the analog-to-digital converter (ADC) raw data.

    Attributes:
        verbose: Verbosity of output.
        raw_input_path: Path with the ROOT files to be imported.
        raw_input_fileslist: Array of ROOT files to be imported.
        adc_f: ADC sampling frequency in samples per second.
        adc_r: ADC resolution in volts per bin.
        adc_z: ADC input impedance.
        adc_a: Amplification factor of readout.
        elementary_charge: Electron charge in C.
        adc_area_to_e: Conversion factor pulse area in ADC units to charge in units of elementary charge.
    &#34;&#34;&#34;

    def __init__(self, raw_input_path: str, raw_input_filepattern: str = &#39;*.root&#39;,
                 adc_type: str = &#39;v1730d&#39;, verbose: bool = False):
        &#34;&#34;&#34;Init of the ADCRawData class.

        Defines the list of files to be loaded and global parameters from the data acquisition.

        Args:
            raw_input_path: Path with the ROOT files to be imported.
            raw_input_filepattern: Name of file or pattern of files to be imported. Default: `*root` for
                all ROOT files in `raw_input_path`.
            adc_type: ADC model used for the data acquisition. Options: `v1724`, `v1730d` (default).
            verbose: Set verbose output.
        &#34;&#34;&#34;
        self.verbose = verbose
        self.raw_input_path = raw_input_path
        self.raw_input_fileslist = glob.glob(os.path.join(raw_input_path, raw_input_filepattern))
        if len(self.raw_input_fileslist) == 0:
            raise ValueError(&#39;No files found to be loaded. Provide valid path and filename pattern.&#39;)
        elif &#39;.root&#39; not in &#39; &#39;.join(self.raw_input_fileslist):
            raise TypeError(&#39;There seem to be no .root files among the selected files.&#39;)
        elif self.verbose:
            print(&#39;Selected following files to be loaded:&#39;)
            print(*[el.split(os.sep)[-1] for el in self.raw_input_fileslist], sep=&#34;\n&#34;)
        # Define conversion factors depending on ADC type
        self.get_conversion_factors(adc_type)

    def get_conversion_factors(self, adc_type: str):
        &#34;&#34;&#34;Define global conversion factors depending on ADC type.

        Args:
            adc_type: ADC model used for the data acquisition. Options: `v1724`, `v1730d`.
        &#34;&#34;&#34;
        self.elementary_charge = 1.60218e-19  # electron charge
        if str(adc_type).lower() in [&#39;v1730d&#39;, &#39;v1730&#39;, &#39;1730&#39;, &#39;1730d&#39;]:  # CAEN V1730D
            self.adc_f = 500e6  # ADC sampling frequency: 500 MS/s digitization speed (2 ns bins)
            self.adc_r = 2.0 / 2 ** 14  # ADC resolution in volts per bin: 14 bit ADC, 2V voltage range
            self.adc_z = 50  # input impedance: 50 Ohm termination to ground
            self.adc_a = 10  # amplification factor: 10 times gain into 50 Ohm impedance
        elif str(adc_type).lower() in [&#39;v1724&#39;, &#39;1724&#39;]:  # CAEN V1730D
            self.adc_f = 100e6  # ADC sampling frequency: 100 MS/s digitization speed (10 ns bins)
            self.adc_r = 2.25 / 2 ** 14  # ADC resolution in volts per bin: 14 bit ADC, 2.25V voltage range
            self.adc_z = 50  # input impedance: 50 Ohm termination to ground
            self.adc_a = 10  # amplification factor: 10 times gain into 50 Ohm impedance
        else:
            raise ValueError(
                &#39;{} is no valid option for `adc_type`. Select from (`v1724`, `v1730d`).&#39;.format(adc_type))
        # Conversion factor pulse area in ADC units to charge in units of elementary charge.
        self.adc_area_to_e = self.adc_r / (self.adc_f * self.adc_z * self.adc_a * self.elementary_charge)

    def set_run_conditions(self):
        &#34;&#34;&#34;Define the run specific conditions.
        TODO: fill, extract info from raw_input_path
        &#34;&#34;&#34;
        pass

    def get_trees(self) -&gt; str:
        &#34;&#34;&#34;Find name of unique available tree in ROOT files to be loaded.

        Returns:
            tree: Unique ROOT tree name.
        &#34;&#34;&#34;
        # Iterate over selected files.
        for i, input_file in enumerate(self.raw_input_fileslist):
            with uproot.open(input_file) as file:
                # Get tree names in file.
                trees_file = file.keys()
                if len(trees_file) == 0:
                    raise ValueError(&#39;No trees found in selected ROOT file {}.&#39;.format(input_file))
                # Convert tree names to string.
                trees_file = [el for el in trees_file]
                # For large data sets, ROOT may generate additional copies of a
                # particular tree, consequently named e.g. `t1;1`, `t1;2`,...
                # We only want the name before the semicolon.
                trees_file = np.unique([el.split(&#39;;&#39;)[0] for el in trees_file])
            # Concatenate with previous iterations.
            if i != 0:
                trees = np.unique(np.concatenate([trees, trees_file], axis=0))
            else:
                trees = trees_file
        # Require and return only one unique tree name.
        if len(trees) &gt; 1:
            raise ValueError(&#39;Multiple ({}) trees found in selected ROOT file.&#39;
                             &#39;Specify single tree to be loaded.&#39;.format(len(trees)))
        else:
            tree = str(trees[0])
        return tree

    def get_branches(self, tree: Optional[str] = None) -&gt; np.ndarray:
        &#34;&#34;&#34;Find branch names in ROOT files to be loaded.

        Args:
            tree: Name of the ROOT tree to be inspected. If `None` deduce with
                `pmt_analysis.utils.input.ADCRawData.get_trees` method.

        Returns:
            branches: Array with branch names in selected ROOT files.
        &#34;&#34;&#34;
        # Define tree to be inspected.
        if tree is None:
            tree = self.get_trees()
        else:
            if type(tree) != str:
                raise TypeError(&#39;Parameter `tree` must be of type `str`.&#39;)
        # Iterate over selected files.
        for i, input_file in enumerate(self.raw_input_fileslist):
            with uproot.open(input_file) as file:
                # Get branch names in given tree.
                branches_file = file[tree].keys()
                if len(branches_file) == 0:
                    raise ValueError(&#39;No branches found for tree {} in selected ROOT file {}.&#39;.format(tree, input_file))
                # Convert branch names to string.
                branches_file = np.array([el for el in branches_file])
            # Concatenate with previous iterations.
            if i != 0:
                branches = np.unique(np.concatenate([branches, branches_file], axis=0))
            else:
                branches = branches_file
        return branches

    def get_branch_data(self, branch: Union[str, int], tree: Optional[str] = None) -&gt; np.ndarray:
        &#34;&#34;&#34;Retrieve data of specified branch and tree in all selected ROOT files.

        Args:
            branch: Branch of ROOT file to be loaded. Also allows for input of an ADC channel number (int).
            tree: ROOT tree to load. If `None` deduce with `pmt_analysis.utils.input.ADCRawData.get_trees` method.
        Returns:
            out: Array with data of selected branch. Typically, Unix timestamp for `branch = &#39;Time&#39;` or
                ADC data of selected channel, e.g. waveforms of channel 0 for `branch = &#39;wf0&#39;` or `branch = 0`.
        &#34;&#34;&#34;
        # Define tree to be inspected.
        if tree is None:
            tree = self.get_trees()
        else:
            if type(tree) != str:
                raise TypeError(&#39;Parameter `tree` must be of type `str`.&#39;)
        # Make optional to pass channel number (int) for branch.
        if type(branch) == int:
            branch = &#39;wf{}&#39;.format(branch)
        if type(branch) != str:
            raise TypeError(&#39;Parameter `branch` must be of type `str` or `int`.&#39;)
        # Check availability of selected branch.
        if branch not in self.get_branches(tree):
            raise ValueError(&#39;Branch {} not found in tree {} of selected ROOT files.&#39;.format(branch, tree))
        # Iteratively load data from ROOT files.
        executor = concurrent.futures.ThreadPoolExecutor(8)
        out = uproot.concatenate(files={el: tree for el in self.raw_input_fileslist},
                                 expressions=branch,
                                 library=&#39;np&#39;,
                                 step_size=100000,
                                 allow_missing=True,
                                 decompression_executor=executor,
                                 interpretation_executor=executor
                                 )[branch]
        return out</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pmt_analysis.utils.input.ADCRawData.get_branch_data"><code class="name flex">
<span>def <span class="ident">get_branch_data</span></span>(<span>self, branch: Union[str, int], tree: Optional[str] = None) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieve data of specified branch and tree in all selected ROOT files.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>branch</code></strong></dt>
<dd>Branch of ROOT file to be loaded. Also allows for input of an ADC channel number (int).</dd>
<dt><strong><code>tree</code></strong></dt>
<dd>ROOT tree to load. If <code>None</code> deduce with <code><a title="pmt_analysis.utils.input.ADCRawData.get_trees" href="#pmt_analysis.utils.input.ADCRawData.get_trees">ADCRawData.get_trees()</a></code> method.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>out</code></dt>
<dd>Array with data of selected branch. Typically, Unix timestamp for <code>branch = 'Time'</code> or
ADC data of selected channel, e.g. waveforms of channel 0 for <code>branch = 'wf0'</code> or <code>branch = 0</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_branch_data(self, branch: Union[str, int], tree: Optional[str] = None) -&gt; np.ndarray:
    &#34;&#34;&#34;Retrieve data of specified branch and tree in all selected ROOT files.

    Args:
        branch: Branch of ROOT file to be loaded. Also allows for input of an ADC channel number (int).
        tree: ROOT tree to load. If `None` deduce with `pmt_analysis.utils.input.ADCRawData.get_trees` method.
    Returns:
        out: Array with data of selected branch. Typically, Unix timestamp for `branch = &#39;Time&#39;` or
            ADC data of selected channel, e.g. waveforms of channel 0 for `branch = &#39;wf0&#39;` or `branch = 0`.
    &#34;&#34;&#34;
    # Define tree to be inspected.
    if tree is None:
        tree = self.get_trees()
    else:
        if type(tree) != str:
            raise TypeError(&#39;Parameter `tree` must be of type `str`.&#39;)
    # Make optional to pass channel number (int) for branch.
    if type(branch) == int:
        branch = &#39;wf{}&#39;.format(branch)
    if type(branch) != str:
        raise TypeError(&#39;Parameter `branch` must be of type `str` or `int`.&#39;)
    # Check availability of selected branch.
    if branch not in self.get_branches(tree):
        raise ValueError(&#39;Branch {} not found in tree {} of selected ROOT files.&#39;.format(branch, tree))
    # Iteratively load data from ROOT files.
    executor = concurrent.futures.ThreadPoolExecutor(8)
    out = uproot.concatenate(files={el: tree for el in self.raw_input_fileslist},
                             expressions=branch,
                             library=&#39;np&#39;,
                             step_size=100000,
                             allow_missing=True,
                             decompression_executor=executor,
                             interpretation_executor=executor
                             )[branch]
    return out</code></pre>
</details>
</dd>
<dt id="pmt_analysis.utils.input.ADCRawData.get_branches"><code class="name flex">
<span>def <span class="ident">get_branches</span></span>(<span>self, tree: Optional[str] = None) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Find branch names in ROOT files to be loaded.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>tree</code></strong></dt>
<dd>Name of the ROOT tree to be inspected. If <code>None</code> deduce with
<code><a title="pmt_analysis.utils.input.ADCRawData.get_trees" href="#pmt_analysis.utils.input.ADCRawData.get_trees">ADCRawData.get_trees()</a></code> method.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>branches</code></dt>
<dd>Array with branch names in selected ROOT files.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_branches(self, tree: Optional[str] = None) -&gt; np.ndarray:
    &#34;&#34;&#34;Find branch names in ROOT files to be loaded.

    Args:
        tree: Name of the ROOT tree to be inspected. If `None` deduce with
            `pmt_analysis.utils.input.ADCRawData.get_trees` method.

    Returns:
        branches: Array with branch names in selected ROOT files.
    &#34;&#34;&#34;
    # Define tree to be inspected.
    if tree is None:
        tree = self.get_trees()
    else:
        if type(tree) != str:
            raise TypeError(&#39;Parameter `tree` must be of type `str`.&#39;)
    # Iterate over selected files.
    for i, input_file in enumerate(self.raw_input_fileslist):
        with uproot.open(input_file) as file:
            # Get branch names in given tree.
            branches_file = file[tree].keys()
            if len(branches_file) == 0:
                raise ValueError(&#39;No branches found for tree {} in selected ROOT file {}.&#39;.format(tree, input_file))
            # Convert branch names to string.
            branches_file = np.array([el for el in branches_file])
        # Concatenate with previous iterations.
        if i != 0:
            branches = np.unique(np.concatenate([branches, branches_file], axis=0))
        else:
            branches = branches_file
    return branches</code></pre>
</details>
</dd>
<dt id="pmt_analysis.utils.input.ADCRawData.get_conversion_factors"><code class="name flex">
<span>def <span class="ident">get_conversion_factors</span></span>(<span>self, adc_type: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Define global conversion factors depending on ADC type.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>adc_type</code></strong></dt>
<dd>ADC model used for the data acquisition. Options: <code>v1724</code>, <code>v1730d</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_conversion_factors(self, adc_type: str):
    &#34;&#34;&#34;Define global conversion factors depending on ADC type.

    Args:
        adc_type: ADC model used for the data acquisition. Options: `v1724`, `v1730d`.
    &#34;&#34;&#34;
    self.elementary_charge = 1.60218e-19  # electron charge
    if str(adc_type).lower() in [&#39;v1730d&#39;, &#39;v1730&#39;, &#39;1730&#39;, &#39;1730d&#39;]:  # CAEN V1730D
        self.adc_f = 500e6  # ADC sampling frequency: 500 MS/s digitization speed (2 ns bins)
        self.adc_r = 2.0 / 2 ** 14  # ADC resolution in volts per bin: 14 bit ADC, 2V voltage range
        self.adc_z = 50  # input impedance: 50 Ohm termination to ground
        self.adc_a = 10  # amplification factor: 10 times gain into 50 Ohm impedance
    elif str(adc_type).lower() in [&#39;v1724&#39;, &#39;1724&#39;]:  # CAEN V1730D
        self.adc_f = 100e6  # ADC sampling frequency: 100 MS/s digitization speed (10 ns bins)
        self.adc_r = 2.25 / 2 ** 14  # ADC resolution in volts per bin: 14 bit ADC, 2.25V voltage range
        self.adc_z = 50  # input impedance: 50 Ohm termination to ground
        self.adc_a = 10  # amplification factor: 10 times gain into 50 Ohm impedance
    else:
        raise ValueError(
            &#39;{} is no valid option for `adc_type`. Select from (`v1724`, `v1730d`).&#39;.format(adc_type))
    # Conversion factor pulse area in ADC units to charge in units of elementary charge.
    self.adc_area_to_e = self.adc_r / (self.adc_f * self.adc_z * self.adc_a * self.elementary_charge)</code></pre>
</details>
</dd>
<dt id="pmt_analysis.utils.input.ADCRawData.get_trees"><code class="name flex">
<span>def <span class="ident">get_trees</span></span>(<span>self) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Find name of unique available tree in ROOT files to be loaded.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tree</code></dt>
<dd>Unique ROOT tree name.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_trees(self) -&gt; str:
    &#34;&#34;&#34;Find name of unique available tree in ROOT files to be loaded.

    Returns:
        tree: Unique ROOT tree name.
    &#34;&#34;&#34;
    # Iterate over selected files.
    for i, input_file in enumerate(self.raw_input_fileslist):
        with uproot.open(input_file) as file:
            # Get tree names in file.
            trees_file = file.keys()
            if len(trees_file) == 0:
                raise ValueError(&#39;No trees found in selected ROOT file {}.&#39;.format(input_file))
            # Convert tree names to string.
            trees_file = [el for el in trees_file]
            # For large data sets, ROOT may generate additional copies of a
            # particular tree, consequently named e.g. `t1;1`, `t1;2`,...
            # We only want the name before the semicolon.
            trees_file = np.unique([el.split(&#39;;&#39;)[0] for el in trees_file])
        # Concatenate with previous iterations.
        if i != 0:
            trees = np.unique(np.concatenate([trees, trees_file], axis=0))
        else:
            trees = trees_file
    # Require and return only one unique tree name.
    if len(trees) &gt; 1:
        raise ValueError(&#39;Multiple ({}) trees found in selected ROOT file.&#39;
                         &#39;Specify single tree to be loaded.&#39;.format(len(trees)))
    else:
        tree = str(trees[0])
    return tree</code></pre>
</details>
</dd>
<dt id="pmt_analysis.utils.input.ADCRawData.set_run_conditions"><code class="name flex">
<span>def <span class="ident">set_run_conditions</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Define the run specific conditions.
TODO: fill, extract info from raw_input_path</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_run_conditions(self):
    &#34;&#34;&#34;Define the run specific conditions.
    TODO: fill, extract info from raw_input_path
    &#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pmt_analysis.utils.input.ScalerRawData"><code class="flex name class">
<span>class <span class="ident">ScalerRawData</span></span>
<span>(</span><span>files: Union[str, list], trim_empty: bool = True, verbose: bool = True)</span>
</code></dt>
<dd>
<div class="desc"><p>General class to import the CAEN V260 scaler raw data from space-separated <code>.dat</code> files.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>verbose</code></strong></dt>
<dd>Verbosity of output.</dd>
<dt><strong><code>trim_empty</code></strong></dt>
<dd>Remove columns for non-active channels.</dd>
<dt><strong><code>files</code></strong></dt>
<dd>List of full file path and name of all <code>.dat</code> files to be loaded.</dd>
<dt><strong><code>t_int</code></strong></dt>
<dd>Data acquisition interval in seconds.</dd>
</dl>
<p>Init of the ScalerRawData class.</p>
<p>Defines the list of files to be loaded and global parameters from the data acquisition.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>files</code></strong></dt>
<dd>Files to be loaded. Possible formats:
String of full file path and name for a single file to be loaded;
list of strings of full file paths and names for multiple files to be loaded;
string of full file path for the parent directory of all <code>.dat</code> files to be loaded.</dd>
<dt><strong><code>trim_empty</code></strong></dt>
<dd>Remove columns for non-active channels.</dd>
<dt><strong><code>verbose</code></strong></dt>
<dd>Verbosity of output.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ScalerRawData:
    &#34;&#34;&#34;General class to import the CAEN V260 scaler raw data from space-separated `.dat` files.

    Attributes:
        verbose: Verbosity of output.
        trim_empty: Remove columns for non-active channels.
        files: List of full file path and name of all `.dat` files to be loaded.
        t_int: Data acquisition interval in seconds.
    &#34;&#34;&#34;

    def __init__(self, files: Union[str, list], trim_empty: bool = True, verbose: bool = True):
        &#34;&#34;&#34;Init of the ScalerRawData class.

        Defines the list of files to be loaded and global parameters from the data acquisition.

        Args:
            files: Files to be loaded. Possible formats: 
                String of full file path and name for a single file to be loaded; 
                list of strings of full file paths and names for multiple files to be loaded; 
                string of full file path for the parent directory of all `.dat` files to be loaded.
            trim_empty: Remove columns for non-active channels.
            verbose: Verbosity of output.
        &#34;&#34;&#34;
        self.verbose = verbose
        self.trim_empty = trim_empty
        self.files = self.convert_input_path(input_str_or_list=files)
        if verbose:
            print(&#39;Files to be loaded:&#39;)
            print(*self.files, sep=&#34;\n&#34;)
        self.t_int = self.get_t_int()
        if verbose:
            print(&#39;Data acquisition interval: {} s&#39;.format(self.t_int))

    @staticmethod
    def convert_input_path(input_str_or_list: Union[str, list]) -&gt; list:
        &#34;&#34;&#34;Convert `input` parameter to appropriate format, 
        i.e. list of strings indicating full file paths and names.

        Args:
            input_str_or_list: Files to be loaded. Possible formats:
                String of full file path and name for a single file to be loaded;
                list of strings of full file paths and names for multiple files to be loaded;
                string of full file path for the parent directory of all `.dat` files to be loaded.
        &#34;&#34;&#34;
        # Construct list of strings with paths and names of files to be loaded.
        if type(input_str_or_list) == str:
            if os.path.isfile(input_str_or_list):
                output_list = [input_str_or_list]  # single file name to list
            elif os.path.isdir(input_str_or_list):
                output_list = glob.glob(os.path.join(input_str_or_list, &#39;*.dat&#39;))  # find all .dat files in directory
                if len(output_list) &lt; 1:
                    raise ValueError(&#39;No files found to be loaded.&#39;)
            else:
                raise ValueError(&#39;Cannot access {}: No such file or directory&#39;.format(input_str_or_list))
        elif type(input_str_or_list) != list:
            raise TypeError(&#39;Values for file parameter must be of type str or list, &#39;
                            &#39;but is of type {}.&#39;.format(type(input_str_or_list)))
        else:
            output_list = input_str_or_list

        # Remove possible file names not in .dat format.
        if np.any(~np.array([&#39;.dat&#39; in el for el in output_list])):
            warnings.warn(&#39;Removing files not in .dat format.&#39;)
            output_list = [el for el in output_list if &#39;.dat&#39; in el]
            if len(output_list) &lt; 1:
                raise ValueError(&#39;No files found to be loaded.&#39;)

        return output_list

    def get_t_int(self) -&gt; int:
        &#34;&#34;&#34;Get data acquisition interval and ensure that all files have the same acquisition interval.

        Returns:
            t_int: Data acquisition interval in seconds.
        &#34;&#34;&#34;
        # Obtain acquisition intervals from files to be loaded.
        t_int_list = []
        for file in self.files:
            with open(file) as f:
                first_line = f.readline().strip(&#39;\n&#39;).split(&#39; &#39;)
                t_int_list.append(int(first_line[first_line.index(&#39;Interval:&#39;) + 1]))
        # Ensure that all files have the same acquisition interval.
        if np.unique(t_int_list).shape[0] == 1:
            t_int = t_int_list[0]
        else:
            raise ValueError(&#39;Loaded files have different acquisition intervals.&#39;)

        return t_int

    def get_data(self) -&gt; pd.DataFrame:
        &#34;&#34;&#34;Load scaler data.

        Returns:
            df: Pandas data frame with scaler data. Contains timestamps, datetimes, as well as counts (`ch*_cnts`)
                and count rates (`ch*_freq`) in the respective data acquisition intervals for the individual channels.
        &#34;&#34;&#34;
        scaler_column_names = np.concatenate([np.array([&#39;timestamp&#39;]),
                                              np.array([[&#39;ch{}_cnts&#39;.format(i), &#39;ch{}_freq&#39;.format(i)]
                                                        for i in range(16)]).flatten()])
        df_list = (pd.read_csv(file, sep=&#39;\s+&#39;, lineterminator=&#39;\n&#39;, skiprows=1,
                               header=None, names=scaler_column_names) for file in self.files)
        df = pd.concat(df_list, ignore_index=True)

        # Remove columns with no counts
        if self.trim_empty:
            df.drop(df.columns[df.mean(axis=0) &lt; 1e-3], axis=1, inplace=True)

        return df</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="pmt_analysis.utils.input.ScalerRawData.convert_input_path"><code class="name flex">
<span>def <span class="ident">convert_input_path</span></span>(<span>input_str_or_list: Union[str, list]) ‑> list</span>
</code></dt>
<dd>
<div class="desc"><p>Convert <code>input</code> parameter to appropriate format,
i.e. list of strings indicating full file paths and names.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input_str_or_list</code></strong></dt>
<dd>Files to be loaded. Possible formats:
String of full file path and name for a single file to be loaded;
list of strings of full file paths and names for multiple files to be loaded;
string of full file path for the parent directory of all <code>.dat</code> files to be loaded.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def convert_input_path(input_str_or_list: Union[str, list]) -&gt; list:
    &#34;&#34;&#34;Convert `input` parameter to appropriate format, 
    i.e. list of strings indicating full file paths and names.

    Args:
        input_str_or_list: Files to be loaded. Possible formats:
            String of full file path and name for a single file to be loaded;
            list of strings of full file paths and names for multiple files to be loaded;
            string of full file path for the parent directory of all `.dat` files to be loaded.
    &#34;&#34;&#34;
    # Construct list of strings with paths and names of files to be loaded.
    if type(input_str_or_list) == str:
        if os.path.isfile(input_str_or_list):
            output_list = [input_str_or_list]  # single file name to list
        elif os.path.isdir(input_str_or_list):
            output_list = glob.glob(os.path.join(input_str_or_list, &#39;*.dat&#39;))  # find all .dat files in directory
            if len(output_list) &lt; 1:
                raise ValueError(&#39;No files found to be loaded.&#39;)
        else:
            raise ValueError(&#39;Cannot access {}: No such file or directory&#39;.format(input_str_or_list))
    elif type(input_str_or_list) != list:
        raise TypeError(&#39;Values for file parameter must be of type str or list, &#39;
                        &#39;but is of type {}.&#39;.format(type(input_str_or_list)))
    else:
        output_list = input_str_or_list

    # Remove possible file names not in .dat format.
    if np.any(~np.array([&#39;.dat&#39; in el for el in output_list])):
        warnings.warn(&#39;Removing files not in .dat format.&#39;)
        output_list = [el for el in output_list if &#39;.dat&#39; in el]
        if len(output_list) &lt; 1:
            raise ValueError(&#39;No files found to be loaded.&#39;)

    return output_list</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pmt_analysis.utils.input.ScalerRawData.get_data"><code class="name flex">
<span>def <span class="ident">get_data</span></span>(<span>self) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Load scaler data.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>df</code></dt>
<dd>Pandas data frame with scaler data. Contains timestamps, datetimes, as well as counts (<code>ch*_cnts</code>)
and count rates (<code>ch*_freq</code>) in the respective data acquisition intervals for the individual channels.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_data(self) -&gt; pd.DataFrame:
    &#34;&#34;&#34;Load scaler data.

    Returns:
        df: Pandas data frame with scaler data. Contains timestamps, datetimes, as well as counts (`ch*_cnts`)
            and count rates (`ch*_freq`) in the respective data acquisition intervals for the individual channels.
    &#34;&#34;&#34;
    scaler_column_names = np.concatenate([np.array([&#39;timestamp&#39;]),
                                          np.array([[&#39;ch{}_cnts&#39;.format(i), &#39;ch{}_freq&#39;.format(i)]
                                                    for i in range(16)]).flatten()])
    df_list = (pd.read_csv(file, sep=&#39;\s+&#39;, lineterminator=&#39;\n&#39;, skiprows=1,
                           header=None, names=scaler_column_names) for file in self.files)
    df = pd.concat(df_list, ignore_index=True)

    # Remove columns with no counts
    if self.trim_empty:
        df.drop(df.columns[df.mean(axis=0) &lt; 1e-3], axis=1, inplace=True)

    return df</code></pre>
</details>
</dd>
<dt id="pmt_analysis.utils.input.ScalerRawData.get_t_int"><code class="name flex">
<span>def <span class="ident">get_t_int</span></span>(<span>self) ‑> int</span>
</code></dt>
<dd>
<div class="desc"><p>Get data acquisition interval and ensure that all files have the same acquisition interval.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>t_int</code></dt>
<dd>Data acquisition interval in seconds.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_t_int(self) -&gt; int:
    &#34;&#34;&#34;Get data acquisition interval and ensure that all files have the same acquisition interval.

    Returns:
        t_int: Data acquisition interval in seconds.
    &#34;&#34;&#34;
    # Obtain acquisition intervals from files to be loaded.
    t_int_list = []
    for file in self.files:
        with open(file) as f:
            first_line = f.readline().strip(&#39;\n&#39;).split(&#39; &#39;)
            t_int_list.append(int(first_line[first_line.index(&#39;Interval:&#39;) + 1]))
    # Ensure that all files have the same acquisition interval.
    if np.unique(t_int_list).shape[0] == 1:
        t_int = t_int_list[0]
    else:
        raise ValueError(&#39;Loaded files have different acquisition intervals.&#39;)

    return t_int</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pmt_analysis.utils" href="index.html">pmt_analysis.utils</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pmt_analysis.utils.input.ADCRawData" href="#pmt_analysis.utils.input.ADCRawData">ADCRawData</a></code></h4>
<ul class="">
<li><code><a title="pmt_analysis.utils.input.ADCRawData.get_branch_data" href="#pmt_analysis.utils.input.ADCRawData.get_branch_data">get_branch_data</a></code></li>
<li><code><a title="pmt_analysis.utils.input.ADCRawData.get_branches" href="#pmt_analysis.utils.input.ADCRawData.get_branches">get_branches</a></code></li>
<li><code><a title="pmt_analysis.utils.input.ADCRawData.get_conversion_factors" href="#pmt_analysis.utils.input.ADCRawData.get_conversion_factors">get_conversion_factors</a></code></li>
<li><code><a title="pmt_analysis.utils.input.ADCRawData.get_trees" href="#pmt_analysis.utils.input.ADCRawData.get_trees">get_trees</a></code></li>
<li><code><a title="pmt_analysis.utils.input.ADCRawData.set_run_conditions" href="#pmt_analysis.utils.input.ADCRawData.set_run_conditions">set_run_conditions</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pmt_analysis.utils.input.ScalerRawData" href="#pmt_analysis.utils.input.ScalerRawData">ScalerRawData</a></code></h4>
<ul class="">
<li><code><a title="pmt_analysis.utils.input.ScalerRawData.convert_input_path" href="#pmt_analysis.utils.input.ScalerRawData.convert_input_path">convert_input_path</a></code></li>
<li><code><a title="pmt_analysis.utils.input.ScalerRawData.get_data" href="#pmt_analysis.utils.input.ScalerRawData.get_data">get_data</a></code></li>
<li><code><a title="pmt_analysis.utils.input.ScalerRawData.get_t_int" href="#pmt_analysis.utils.input.ScalerRawData.get_t_int">get_t_int</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>