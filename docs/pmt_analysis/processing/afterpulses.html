<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>pmt_analysis.processing.afterpulses API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pmt_analysis.processing.afterpulses</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import warnings

import numpy as np
import pandas as pd
from tqdm import tqdm
from scipy.signal import find_peaks
from pmt_analysis.processing.basics import FullWindow
import collections
from typing import Optional


class AfterPulses:
    &#34;&#34;&#34;Afterpulse finding and processing.

    Attributes:
        input_data: Array with ADC data of shape (number of waveforms, time bins per waveform).
        input_data_std: Standard deviation of the input data baseline per waveform.
        verbose: Set verbose output.
        adc_f: ADC sampling frequency in samples per second as provided by same attribute of
            `pmt_analysis.utils.input.ADCRawData`.
        occupancy: Occupancy of the main pulse in PE per (LED) trigger.
        occupancy_unc: Occupancy uncertainty of the main pulse in PE per (LED) trigger.
        amp_thr_ap: Lower amplitude threshold for afterpulse candidates.
        n_samples: Total number of waveforms analyzed.
        df: Pandas dataframe with after pulse candidates and their properties.
        ap_rate_dict: Dictionary with resulting afterpulse rate value and uncertainty.
    &#34;&#34;&#34;

    def __init__(self, input_data: np.ndarray, adc_f: float, verbose: bool = True,
                 pre_filter_threshold: float = 3, pre_filter_threshold_type: str = &#39;std&#39;,
                 occupancy: Optional[float] = None, occupancy_unc: Optional[float] = None,
                 amp_thr_ap: Optional[float] = None):
        &#34;&#34;&#34;Init of the AfterPulses class.

        Args:
            input_data: Array with ADC data of shape (number of waveforms, time bins per waveform) as
                provided by `pmt_analysis.utils.input.ADCRawData`.
            verbose: Set verbose output.
            pre_filter_threshold: Amplitude threshold to exclude waveforms that do not contain any entries above
                threshold (i.e. no main pulse or afterpulse of a certain minimum size) to make further processing
                more efficient. Set to a negative value to effectively disable pre-filtering.
            pre_filter_threshold_type: &#39;abs&#39; for absolute threshold or &#39;std&#39; for thresholds of multiples of the
                baseline standard deviation.
            adc_f: ADC sampling frequency in samples per second as provided by same attribute of
                `pmt_analysis.utils.input.ADCRawData`.
            occupancy: Occupancy of the main pulse in PE per (LED) trigger.
            occupancy_unc: Occupancy uncertainty of the main pulse in PE per (LED) trigger.
            amp_thr_ap: Lower amplitude threshold for afterpulse candidates.
        &#34;&#34;&#34;
        self.adc_f = adc_f
        self.occupancy = occupancy
        self.occupancy_unc = occupancy_unc
        self.amp_thr_ap = amp_thr_ap
        self.input_data = input_data
        self.input_data_std = FullWindow().get_baseline_std(self.input_data)
        self.verbose = verbose
        self.n_samples = self.input_data.shape[0]
        self.df = pd.DataFrame()
        self.ap_rate_dict = {}
        # Remove waveforms containing no entries above some threshold (i.e. no main pulse or afterpulse).
        if pre_filter_threshold_type == &#39;std&#39;:
            self.pre_filter(amplitude_threshold_abs=None, amplitude_threshold_std=pre_filter_threshold)
        elif pre_filter_threshold_type == &#39;abs&#39;:
            self.pre_filter(amplitude_threshold_abs=pre_filter_threshold, amplitude_threshold_std=None)
        else:
            raise ValueError(&#39;Parameter pre_filter_threshold_type can only take values abs or std.&#39;)

    def pre_filter(self, amplitude_threshold_abs: Optional[float] = None,
                   amplitude_threshold_std: Optional[float] = 3):
        &#34;&#34;&#34;Method to exclude waveforms that do not contain any entries above an amplitude threshold,
        i.e. no main pulse or afterpulse of a certain minimum size, in order to make further processing
        more efficient.

        Args:
            amplitude_threshold_abs: Absolute amplitude threshold. Default: None (disabled).
            amplitude_threshold_std: Amplitude threshold in units of baseline standard deviations.
                Ensure that the signal-to-noise ratio is sufficient for the selected value. Default: 3.
        &#34;&#34;&#34;
        if (amplitude_threshold_abs is not None) and (amplitude_threshold_std is not None):
            raise ValueError(&#39;Either amplitude_threshold_abs or amplitude_threshold_std must be None &#39;
                             &#39;to be disabled, using both options is not permitted.&#39;)
        elif (amplitude_threshold_abs is None) and (amplitude_threshold_std is None):
            raise ValueError(&#39;Either amplitude_threshold_abs or amplitude_threshold_std must have &#39;
                             &#39;a finite value.&#39;)
        amplitudes = FullWindow().get_amplitude(self.input_data)
        if amplitude_threshold_abs is not None:
            if self.verbose:
                print(&#39;Pre-filtering data with absolute threshold {}.&#39;.format(amplitude_threshold_abs))
            self.input_data = self.input_data[amplitudes &gt; amplitude_threshold_abs]
        elif amplitude_threshold_std is not None:
            if self.verbose:
                print(&#39;Pre-filtering data with threshold at {} baseline &#39;
                      &#39;standard deviations.&#39;.format(amplitude_threshold_std))
            thresholds = amplitude_threshold_std * self.input_data_std
            self.input_data = self.input_data[amplitudes &gt; thresholds]
            self.input_data_std = self.input_data_std[amplitudes &gt; thresholds]

    @staticmethod
    def convert_to_amplitude(input_data: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;Convert input_data ADC values to baseline-subtracted and sign reversed values
        (i.e. equivalent to amplitude definition).

        Args:
            input_data: Array with ADC data of shape (number of waveforms, time bins per waveform).

        Returns:
            output: Baseline-subtracted and sign reversed input values.
        &#34;&#34;&#34;
        baselines = FullWindow().get_baseline(input_data)
        output = - np.subtract(input_data.T, baselines).T

        return output

    def find_ap(self, height: float, distance: float = 6, prominence_std: float = 8):
        &#34;&#34;&#34;Find waveforms with at least two pulses using `scipy.signal.find_peaks`.
        The `df` attribute will be expanded by the following columns:

        - `idx`: running index to indicate waveforms with more than two found pulses
        - `input_data_converted`: baseline-subtracted and sign reversed afterpulse candidate waveform values
        - `input_data_std`: baseline standard deviation
        - `p0_position`: index position of first found pulse
        - `p1_position`: index position of afterpulse candidate

        For large datasets, the input_data attribute gets overwritten to save memory, as it won&#39;t be used
        anymore thereafter, and it is still implicitly available through `df.input_data_converted`.

        Args:
            height: Required height of peaks. Fixed threshold above noise, deduced from amplitude spectrum.
            distance: Required minimal horizontal distance (&gt;= 1) in samples between neighbouring peaks.
                Smaller peaks are removed first until the condition is fulfilled for all remaining peaks.
            prominence_std: Required prominence of peaks in units of baseline standard deviations.
        &#34;&#34;&#34;
        if self.verbose:
            print(&#39;Finding waveforms with afterpulse candidates.&#39;)
        input_data_converted = self.convert_to_amplitude(self.input_data)
        prominence = prominence_std * FullWindow().get_baseline_std(self.input_data)

        # Overwrite self.input_data for large data sets to save memory, as it won&#39;t be used anymore hereafter,
        # and it is still implicitly available through `df.input_data_converted`.
        if self.input_data.shape[0] &gt; 5e5:
            warnings.warn(&#39;Overwriting input_data attribute to save memory, &#39;
                          &#39;use df.input_data_converted attribute instead.&#39;)
            self.input_data = np.array([&#39;Removed to save memory, use df.input_data_converted attribute instead.&#39;])

        idx = 0
        for i, el in tqdm(enumerate(input_data_converted)):  # TODO: try to vectorize
            peak_positions, _ = find_peaks(el,
                                           height=height,
                                           prominence=prominence[i],
                                           distance=distance)
            if peak_positions.shape[0] &gt; 1:
                p0_position = peak_positions[0]
                input_data_std = self.input_data_std[i]
                for p1_position in peak_positions[1:]:
                    df_add = pd.DataFrame({&#39;idx&#39;: [idx],
                                           &#39;input_data_converted&#39;: [el.tolist()],
                                           &#39;input_data_std&#39;: input_data_std,
                                           &#39;p0_position&#39;: [p0_position],
                                           &#39;p1_position&#39;: [p1_position]})
                    self.df = pd.concat([self.df, df_add])
                idx += 1
        self.df.reset_index(drop=True, inplace=True)

    def constrain_main_peak(self, trim: bool = True):
        &#34;&#34;&#34;Identify whether the first found pulse is a viable candidate for the main pulse
        (e.g. the LED induced signal) based on its timing compared to the other main pulse candidates.

        Args:
            trim: If `True`, remove events where the first found pulse is not a viable candidate for the main pulse and
                hence the afterpulse event may be misidentified. If `False` only add column `valid_main_pulse` to `df`.
        &#34;&#34;&#34;
        # Define relevant percentiles
        lp = np.percentile(self.df[&#39;p0_position&#39;], (100 - 68.27) / 2)
        cp = np.percentile(self.df[&#39;p0_position&#39;], 50)
        up = np.percentile(self.df[&#39;p0_position&#39;], 100 - (100 - 68.27) / 2)
        sf = 5  # acceptable Gaussian standard deviations from median
        lt = cp - sf * (cp - lp)
        ut = cp + sf * (up - cp)

        # Apply main peak thresholds
        valid_main_pulse = (self.df[&#39;p0_position&#39;] &gt;= lt) &amp; (self.df[&#39;p0_position&#39;] &lt;= ut)
        if trim:
            if self.verbose:
                print(&#39;Constraining main peak.&#39;)
            self.df = self.df[valid_main_pulse]
            self.df.drop([&#39;valid_main_pulse&#39;], axis=1, errors=&#39;ignore&#39;, inplace=True)
        else:
            self.df[&#39;valid_main_pulse&#39;] = valid_main_pulse

    def get_ap_properties(self):
        &#34;&#34;&#34;Calculate properties of found main pulse and afterpulse candidates and add corresponding columns to `df`.

        - `t_diff_ns`: Temporal difference main pulse and afterpulse in ns.
        - `p0_amplitude`: Amplitude of the main pulse candidate (in ADC bins).
        - `p1_amplitude`: Amplitude of the afterpulse candidate (in ADC bins).
        - `p0_lower_bound`: Lower bound of main pulse candidate integration window.
        - `p0_upper_bound`: Upper bound of main pulse candidate integration window.
        - `p0_area`: Area of main pulse candidate.
        - `p1_lower_bound`: Lower bound of afterpulse candidate integration window.
        - `p1_upper_bound`: Upper bound of afterpulse candidate integration window.
        - `p1_area`: Area of afterpulse candidate.
        - `separable`: Boolean stating whether main pulse and afterpulse candidates are separable and not overlapping.
            Only if true, area and amplitude calculations are reliable.
        &#34;&#34;&#34;
        if self.verbose:
            print(&#39;Calculating peak properties.&#39;)
        # Temporal difference main pulse and afterpulse
        self.df[&#39;t_diff_ns&#39;] = (self.df[&#39;p1_position&#39;] - self.df[&#39;p0_position&#39;]) / (self.adc_f * 1e-9)

        # Amplitudes found pulses
        self.df[&#39;p0_amplitude&#39;] = np.array(self.df[&#39;input_data_converted&#39;].tolist())[np.arange(self.df.shape[0]),
                                                                                     np.array(self.df[&#39;p0_position&#39;])]
        self.df[&#39;p1_amplitude&#39;] = np.array(self.df[&#39;input_data_converted&#39;].tolist())[np.arange(self.df.shape[0]),
                                                                                     np.array(self.df[&#39;p1_position&#39;])]
        # Peak ranges and areas
        valley = np.zeros(self.df.shape[0])
        p0_lower_bound = np.zeros(self.df.shape[0], dtype=int)
        p0_upper_bound = np.zeros(self.df.shape[0], dtype=int)
        p0_area = np.zeros(self.df.shape[0])
        p1_lower_bound = np.zeros(self.df.shape[0], dtype=int)
        p1_upper_bound = np.zeros(self.df.shape[0], dtype=int)
        p1_area = np.zeros(self.df.shape[0])
        separable = np.zeros(self.df.shape[0], dtype=bool)

        for i, el in enumerate(self.df[&#39;input_data_converted&#39;]):
            # Position of the lowest value between identified main pulse and afterpulse candidates
            valley[i] = np.argmin(el[self.df[&#39;p0_position&#39;].iloc[i]:self.df[&#39;p1_position&#39;].iloc[i]]) + \
                        self.df[&#39;p0_position&#39;].iloc[i]

            # Lower window bound for main pulse candidate area estimation, take third last entry below
            # one sigma above baseline before main pulse candidate
            try:
                p0_lower_bound[i] = np.where(el[:self.df[&#39;p0_position&#39;].iloc[i]] &lt; self.input_data_std[i])[0][-3]
            except IndexError:
                p0_lower_bound[i] = 0  # unconstrained

            # Upper window bound for main pulse candidate area estimation, take third entry below
            # one sigma above baseline after main pulse candidate or &#39;valley&#39; value
            try:
                p0_upper_bound[i] = (np.where(el[self.df[&#39;p0_position&#39;].iloc[i]:] &lt; self.input_data_std[i])[0][2]) + \
                                    self.df[&#39;p0_position&#39;].iloc[i]
            except IndexError:
                p0_upper_bound[i] = valley[i]  # take &#39;valley&#39; value
            p0_upper_bound[i] = min(p0_upper_bound[i], valley[i])

            # Lower window bound for afterpulse candidate area estimation, take third last entry below
            # one sigma above baseline before afterpulse candidate or &#39;valley&#39; value
            try:
                p1_lower_bound[i] = np.where(el[:self.df[&#39;p1_position&#39;].iloc[i]] &lt; self.input_data_std[i])[0][-3]
            except IndexError:
                p1_lower_bound[i] = valley[i]  # take &#39;valley&#39; value
            p1_lower_bound[i] = max(p1_lower_bound[i], valley[i])

            # Upper window bound for afterpulse candidate area estimation, take third entry below
            # one sigma above baseline after afterpulse candidate
            try:
                p1_upper_bound[i] = (np.where(el[self.df[&#39;p1_position&#39;].iloc[i]:] &lt; self.input_data_std[i])[0][2]) + \
                                    self.df[&#39;p1_position&#39;].iloc[i]
            except IndexError:
                p1_upper_bound[i] = len(el) - 1  # unconstrained

            # Peak areas
            p0_area[i] = np.sum(el[p0_lower_bound[i]:p0_upper_bound[i] + 1])
            p1_area[i] = np.sum(el[p1_lower_bound[i]:p1_upper_bound[i] + 1])

            # Consider main pulse and afterpulse candidates separable if a minimum value between their respective
            # positions of at most 5% main pulse or afterpulse candidate height is reached.
            separable[i] = (el[int(valley[i])] &lt;= 0.05*max(self.df.iloc[i][&#39;p0_amplitude&#39;],
                                                           self.df.iloc[i][&#39;p1_amplitude&#39;]))

        self.df[&#39;p0_lower_bound&#39;] = p0_lower_bound
        self.df[&#39;p0_upper_bound&#39;] = p0_upper_bound
        self.df[&#39;p0_area&#39;] = p0_area
        self.df[&#39;p1_lower_bound&#39;] = p1_lower_bound
        self.df[&#39;p1_upper_bound&#39;] = p1_upper_bound
        self.df[&#39;p1_area&#39;] = p1_area
        self.df[&#39;separable&#39;] = separable

    def multi_ap(self):
        &#34;&#34;&#34;Find multi-afterpulse candidates that are merged in the area estimation.

        Split separable multi-afterpulse candidates in the same waveform and remove duplicate waveforms
        of non-separable, merged multi-afterpulse candidates to avoid double counting
        &#34;&#34;&#34;
        idx_multi_ap = [item for item, count in collections.Counter(self.df.idx.tolist()).items() if count &gt; 1]
        if self.verbose:
            print(&#39;Finding multi-afterpulse candidates that are merged in the area estimation.&#39;)
            print(&#39;Found total of {} multi-afterpulse candidate waveforms out of {} ({} distinct) general afterpulse &#39;
                  &#39;candidate waveforms.&#39;.format(len(idx_multi_ap), self.df.shape[0], len(np.unique(self.df.idx))))
        if len(idx_multi_ap) &gt; 0:
            n_rows = self.df.shape[0]
            # Entries to be modified, only alter values after all iterations
            mods = {&#39;index&#39;: [], &#39;param_name&#39;: [], &#39;param_val&#39;: []}
            duplicates = []
            for i, el in enumerate(self.df[&#39;input_data_converted&#39;]):
                # Check if following afterpulse candidate in same waveform
                if (i &lt; n_rows - 1) and (self.df[&#39;idx&#39;].iloc[i] == self.df[&#39;idx&#39;].iloc[i + 1]):
                    # Check if identified with same integration window
                    if (self.df[&#39;p1_lower_bound&#39;].iloc[i] == self.df[&#39;p1_lower_bound&#39;].iloc[i + 1]) and (
                            self.df[&#39;p1_upper_bound&#39;].iloc[i] == self.df[&#39;p1_upper_bound&#39;].iloc[i + 1]):
                        # Position of the lowest value between present and subsequent afterpulse candidate
                        valley = np.argmin(el[self.df[&#39;p1_position&#39;].iloc[i]:self.df[&#39;p1_position&#39;].iloc[i + 1]]) + \
                                 self.df[&#39;p1_position&#39;].iloc[i]
                        # Check if present and subsequent afterpulse candidate separable,
                        # i.e. valley at most 30% of both peaks
                        separable = (el[valley] &lt;= 0.3 * self.df[&#39;p1_amplitude&#39;].iloc[i]) and (
                                    el[valley] &lt;= 0.3 * self.df[&#39;p1_amplitude&#39;].iloc[i + 1])
                        if separable:
                            mods[&#39;index&#39;].append(self.df.index[i])
                            mods[&#39;param_name&#39;].append(&#39;p1_upper_bound&#39;)
                            mods[&#39;param_val&#39;].append(valley)
                # Check if previous afterpulse candidate in same waveform
                if (i &gt; 0) and (self.df[&#39;idx&#39;].iloc[i] == self.df[&#39;idx&#39;].iloc[i - 1]):
                    # Check if identified with same integration window
                    if (self.df[&#39;p1_lower_bound&#39;].iloc[i] == self.df[&#39;p1_lower_bound&#39;].iloc[i - 1]) and (
                            self.df[&#39;p1_upper_bound&#39;].iloc[i] == self.df[&#39;p1_upper_bound&#39;].iloc[i - 1]):
                        # Position of the lowest value between present and subsequent afterpulse candidate
                        valley = np.argmin(el[self.df[&#39;p1_position&#39;].iloc[i - 1]:self.df[&#39;p1_position&#39;].iloc[i]]) + \
                                 self.df[&#39;p1_position&#39;].iloc[i - 1]
                        # Check if present and subsequent afterpulse candidate separable,
                        # i.e. valley at most 30% of both peaks
                        separable = (el[valley] &lt;= 0.3 * self.df[&#39;p1_amplitude&#39;].iloc[i - 1]) and (
                                    el[valley] &lt;= 0.3 * self.df[&#39;p1_amplitude&#39;].iloc[i])
                        if separable:
                            mods[&#39;index&#39;].append(self.df.index[i])
                            mods[&#39;param_name&#39;].append(&#39;p1_lower_bound&#39;)
                            mods[&#39;param_val&#39;].append(valley)
                        else:
                            duplicates.append(self.df.index[i])

            # Modify integration bounds for separable multi-afterpulse candidates and update area estimate accordingly
            if len(mods[&#39;index&#39;]) &gt; 0:
                for i, ind in enumerate(mods[&#39;index&#39;]):
                    self.df.at[ind, mods[&#39;param_name&#39;][i]] = mods[&#39;param_val&#39;][i]
                    self.df.at[ind, &#39;p1_area&#39;] = np.sum(
                        (self.df.at[ind, &#39;input_data_converted&#39;])[self.df.at[ind, &#39;p1_lower_bound&#39;]:
                                                                  self.df.at[ind, &#39;p1_upper_bound&#39;] + 1])

            # Remove duplicate waveforms of non-separable, merged multi-afterpulse candidates to avoid double counting
            self.df.drop(index=duplicates, inplace=True)

            if self.verbose:
                print(
                    &#39;Found {} yet unsplit afterpulse candidates and removed {} duplicate waveforms of merged &#39;
                    &#39;multi-afterpulse candidates.&#39;.format(len(mods[&#39;index&#39;]), len(duplicates)))
        else:
            if self.verbose:
                print(&#39;No merged multi-afterpulse candidate waveforms found.&#39;)

    def ap_rate(self):
        &#34;&#34;&#34;Calculate afterpulse rates, normalized to the occupancy.

        - `n_ap`: Total number of identified afterpulses.
        - `n_ap_separable`: Total number of identified afterpulses separable from the main pulse.
        - `ap_fraction`: Fraction of waveforms with identified afterpulse(s).
        - `ap_fraction_unc`: Statistical uncertainty of the fraction of waveforms with identified afterpulse(s).
        - `ap_fraction_separable`: Fraction of waveforms with identified afterpulses separable from the main pulse.
        - `ap_fraction_separable_unc`: Statistical uncertainty of the fraction of waveforms with identified \
          afterpulses separable from the main pulse.
        - `ap_rate`: Afterpulse probability in units of afterpulses per PE.
        - `ap_rate_unc`: Uncertainty of the afterpulse probability in units of afterpulses per PE.
        - `ap_rate_separable`: Afterpulse probability in units of afterpulses (separable from the main pulse) per PE.
        - `ap_rate_separable_unc`: Uncertainty of the afterpulse probability in units of afterpulses \
          (separable from the main pulse) per PE.
        - `amp_thr_ap`: Lower amplitude threshold for afterpulse candidates.
        - `ap_rate_separable_above_thr`: Afterpulse probability in units of afterpulses (separable from the main pulse)
          per PE for afterpulse candidates with amplitudes above `amp_thr_ap`.
        - `ap_rate_separable_unc_above_thr`: Uncertainty of the afterpulse probability in units of afterpulses
          (separable from the main pulse) per PE for afterpulse candidates with amplitudes above `amp_thr_ap`.
        &#34;&#34;&#34;
        n_ap = self.df.shape[0]
        n_ap_separable = np.sum(self.df.separable)
        ap_fraction = n_ap / self.n_samples
        ap_fraction_unc = np.sqrt(n_ap) / self.n_samples
        ap_fraction_separable = n_ap_separable / self.n_samples
        ap_fraction_separable_unc = np.sqrt(n_ap_separable) / self.n_samples
        if self.occupancy is None:
            warnings.warn(&#39;No occupancy given, afterpulse rate will not be fully calculated.&#39;)
            ap_rate = None
            ap_rate_unc = None
            ap_rate_separable = None
            ap_rate_separable_unc = None
            ap_rate_separable_above_thr = None
            ap_rate_separable_unc_above_thr = None
        else:
            ap_rate = ap_fraction / self.occupancy
            ap_rate_separable = ap_fraction_separable / self.occupancy
            if self.occupancy_unc is None:
                warnings.warn(&#39;No occupancy uncertainty given, will assume negligible occupancy uncertainty &#39;
                              &#39;for afterpulse rate calculation.&#39;)
                ap_rate_unc = ap_fraction_unc / self.occupancy
                ap_rate_separable_unc = ap_fraction_separable_unc / self.occupancy
            else:
                ap_rate_unc = ap_rate * np.sqrt((ap_fraction_unc/ap_fraction)**2
                                                + (self.occupancy_unc/self.occupancy)**2)
                ap_rate_separable_unc = ap_rate_separable * np.sqrt((ap_fraction_separable_unc /
                                                                     ap_fraction_separable) ** 2
                                                                    + (self.occupancy_unc/self.occupancy) ** 2)
            if self.amp_thr_ap is None:
                warnings.warn(&#39;No lower amplitude threshold for afterpulse candidates provided.&#39;)
                ap_rate_separable_above_thr = None
                ap_rate_separable_unc_above_thr = None
            else:
                n_ap_separable_above_thr = np.sum(self.df.separable &amp; (self.df.p1_amplitude &gt;= self.amp_thr_ap))
                ap_fraction_separable_above_thr = n_ap_separable_above_thr / self.n_samples
                ap_fraction_separable_unc_above_thr = np.sqrt(n_ap_separable_above_thr) / self.n_samples
                ap_rate_separable_above_thr = ap_fraction_separable_above_thr / self.occupancy
                if self.occupancy_unc is None:
                    ap_rate_separable_unc_above_thr = None
                else:
                    ap_rate_separable_unc_above_thr = (ap_rate_separable_above_thr
                                                       * np.sqrt((ap_fraction_separable_unc_above_thr /
                                                                  ap_fraction_separable_above_thr) ** 2
                                                                 + (self.occupancy_unc / self.occupancy) ** 2))

        self.ap_rate_dict = {&#39;n_ap&#39;: n_ap, &#39;n_ap_separable&#39;: n_ap_separable,
                             &#39;ap_fraction&#39;: ap_fraction, &#39;ap_fraction_unc&#39;: ap_fraction_unc,
                             &#39;ap_fraction_separable&#39;: ap_fraction_separable,
                             &#39;ap_fraction_separable_unc&#39;: ap_fraction_separable_unc,
                             &#39;ap_rate&#39;: ap_rate, &#39;ap_rate_unc&#39;: ap_rate_unc,
                             &#39;ap_rate_separable&#39;: ap_rate_separable, &#39;ap_rate_separable_unc&#39;: ap_rate_separable_unc,
                             &#39;amp_thr_ap&#39;: self.amp_thr_ap, &#39;ap_rate_separable_above_thr&#39;: ap_rate_separable_above_thr,
                             &#39;ap_rate_separable_unc_above_thr&#39;: ap_rate_separable_unc_above_thr
                             }

    def compute(self, height: float, distance: float = 6, prominence_std: float = 8,
                constrain_main_peak: bool = True):
        &#34;&#34;&#34;Perform full afterpulse analysis.

        Args:
            height: Required height of peaks. Fixed threshold above noise, deduced from amplitude spectrum.
            distance: Required minimal horizontal distance (&gt;= 1) in samples between neighbouring peaks.
                Smaller peaks are removed first until the condition is fulfilled for all remaining peaks.
            prominence_std: Required prominence of peaks in units of baseline standard deviations.
            constrain_main_peak: Remove events where the first found pulse is not a viable candidate for
                the main pulse.
        &#34;&#34;&#34;
        self.find_ap(height=height, distance=distance, prominence_std=prominence_std)
        self.constrain_main_peak(trim=constrain_main_peak)
        self.get_ap_properties()
        self.multi_ap()
        self.ap_rate()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pmt_analysis.processing.afterpulses.AfterPulses"><code class="flex name class">
<span>class <span class="ident">AfterPulses</span></span>
<span>(</span><span>input_data: numpy.ndarray, adc_f: float, verbose: bool = True, pre_filter_threshold: float = 3, pre_filter_threshold_type: str = 'std', occupancy: Optional[float] = None, occupancy_unc: Optional[float] = None, amp_thr_ap: Optional[float] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Afterpulse finding and processing.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>input_data</code></strong></dt>
<dd>Array with ADC data of shape (number of waveforms, time bins per waveform).</dd>
<dt><strong><code>input_data_std</code></strong></dt>
<dd>Standard deviation of the input data baseline per waveform.</dd>
<dt><strong><code>verbose</code></strong></dt>
<dd>Set verbose output.</dd>
<dt><strong><code>adc_f</code></strong></dt>
<dd>ADC sampling frequency in samples per second as provided by same attribute of
<code><a title="pmt_analysis.utils.input.ADCRawData" href="../utils/input.html#pmt_analysis.utils.input.ADCRawData">ADCRawData</a></code>.</dd>
<dt><strong><code>occupancy</code></strong></dt>
<dd>Occupancy of the main pulse in PE per (LED) trigger.</dd>
<dt><strong><code>occupancy_unc</code></strong></dt>
<dd>Occupancy uncertainty of the main pulse in PE per (LED) trigger.</dd>
<dt><strong><code>amp_thr_ap</code></strong></dt>
<dd>Lower amplitude threshold for afterpulse candidates.</dd>
<dt><strong><code>n_samples</code></strong></dt>
<dd>Total number of waveforms analyzed.</dd>
<dt><strong><code>df</code></strong></dt>
<dd>Pandas dataframe with after pulse candidates and their properties.</dd>
<dt><strong><code>ap_rate_dict</code></strong></dt>
<dd>Dictionary with resulting afterpulse rate value and uncertainty.</dd>
</dl>
<p>Init of the AfterPulses class.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input_data</code></strong></dt>
<dd>Array with ADC data of shape (number of waveforms, time bins per waveform) as
provided by <code><a title="pmt_analysis.utils.input.ADCRawData" href="../utils/input.html#pmt_analysis.utils.input.ADCRawData">ADCRawData</a></code>.</dd>
<dt><strong><code>verbose</code></strong></dt>
<dd>Set verbose output.</dd>
<dt><strong><code>pre_filter_threshold</code></strong></dt>
<dd>Amplitude threshold to exclude waveforms that do not contain any entries above
threshold (i.e. no main pulse or afterpulse of a certain minimum size) to make further processing
more efficient. Set to a negative value to effectively disable pre-filtering.</dd>
<dt><strong><code>pre_filter_threshold_type</code></strong></dt>
<dd>'abs' for absolute threshold or 'std' for thresholds of multiples of the
baseline standard deviation.</dd>
<dt><strong><code>adc_f</code></strong></dt>
<dd>ADC sampling frequency in samples per second as provided by same attribute of
<code><a title="pmt_analysis.utils.input.ADCRawData" href="../utils/input.html#pmt_analysis.utils.input.ADCRawData">ADCRawData</a></code>.</dd>
<dt><strong><code>occupancy</code></strong></dt>
<dd>Occupancy of the main pulse in PE per (LED) trigger.</dd>
<dt><strong><code>occupancy_unc</code></strong></dt>
<dd>Occupancy uncertainty of the main pulse in PE per (LED) trigger.</dd>
<dt><strong><code>amp_thr_ap</code></strong></dt>
<dd>Lower amplitude threshold for afterpulse candidates.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AfterPulses:
    &#34;&#34;&#34;Afterpulse finding and processing.

    Attributes:
        input_data: Array with ADC data of shape (number of waveforms, time bins per waveform).
        input_data_std: Standard deviation of the input data baseline per waveform.
        verbose: Set verbose output.
        adc_f: ADC sampling frequency in samples per second as provided by same attribute of
            `pmt_analysis.utils.input.ADCRawData`.
        occupancy: Occupancy of the main pulse in PE per (LED) trigger.
        occupancy_unc: Occupancy uncertainty of the main pulse in PE per (LED) trigger.
        amp_thr_ap: Lower amplitude threshold for afterpulse candidates.
        n_samples: Total number of waveforms analyzed.
        df: Pandas dataframe with after pulse candidates and their properties.
        ap_rate_dict: Dictionary with resulting afterpulse rate value and uncertainty.
    &#34;&#34;&#34;

    def __init__(self, input_data: np.ndarray, adc_f: float, verbose: bool = True,
                 pre_filter_threshold: float = 3, pre_filter_threshold_type: str = &#39;std&#39;,
                 occupancy: Optional[float] = None, occupancy_unc: Optional[float] = None,
                 amp_thr_ap: Optional[float] = None):
        &#34;&#34;&#34;Init of the AfterPulses class.

        Args:
            input_data: Array with ADC data of shape (number of waveforms, time bins per waveform) as
                provided by `pmt_analysis.utils.input.ADCRawData`.
            verbose: Set verbose output.
            pre_filter_threshold: Amplitude threshold to exclude waveforms that do not contain any entries above
                threshold (i.e. no main pulse or afterpulse of a certain minimum size) to make further processing
                more efficient. Set to a negative value to effectively disable pre-filtering.
            pre_filter_threshold_type: &#39;abs&#39; for absolute threshold or &#39;std&#39; for thresholds of multiples of the
                baseline standard deviation.
            adc_f: ADC sampling frequency in samples per second as provided by same attribute of
                `pmt_analysis.utils.input.ADCRawData`.
            occupancy: Occupancy of the main pulse in PE per (LED) trigger.
            occupancy_unc: Occupancy uncertainty of the main pulse in PE per (LED) trigger.
            amp_thr_ap: Lower amplitude threshold for afterpulse candidates.
        &#34;&#34;&#34;
        self.adc_f = adc_f
        self.occupancy = occupancy
        self.occupancy_unc = occupancy_unc
        self.amp_thr_ap = amp_thr_ap
        self.input_data = input_data
        self.input_data_std = FullWindow().get_baseline_std(self.input_data)
        self.verbose = verbose
        self.n_samples = self.input_data.shape[0]
        self.df = pd.DataFrame()
        self.ap_rate_dict = {}
        # Remove waveforms containing no entries above some threshold (i.e. no main pulse or afterpulse).
        if pre_filter_threshold_type == &#39;std&#39;:
            self.pre_filter(amplitude_threshold_abs=None, amplitude_threshold_std=pre_filter_threshold)
        elif pre_filter_threshold_type == &#39;abs&#39;:
            self.pre_filter(amplitude_threshold_abs=pre_filter_threshold, amplitude_threshold_std=None)
        else:
            raise ValueError(&#39;Parameter pre_filter_threshold_type can only take values abs or std.&#39;)

    def pre_filter(self, amplitude_threshold_abs: Optional[float] = None,
                   amplitude_threshold_std: Optional[float] = 3):
        &#34;&#34;&#34;Method to exclude waveforms that do not contain any entries above an amplitude threshold,
        i.e. no main pulse or afterpulse of a certain minimum size, in order to make further processing
        more efficient.

        Args:
            amplitude_threshold_abs: Absolute amplitude threshold. Default: None (disabled).
            amplitude_threshold_std: Amplitude threshold in units of baseline standard deviations.
                Ensure that the signal-to-noise ratio is sufficient for the selected value. Default: 3.
        &#34;&#34;&#34;
        if (amplitude_threshold_abs is not None) and (amplitude_threshold_std is not None):
            raise ValueError(&#39;Either amplitude_threshold_abs or amplitude_threshold_std must be None &#39;
                             &#39;to be disabled, using both options is not permitted.&#39;)
        elif (amplitude_threshold_abs is None) and (amplitude_threshold_std is None):
            raise ValueError(&#39;Either amplitude_threshold_abs or amplitude_threshold_std must have &#39;
                             &#39;a finite value.&#39;)
        amplitudes = FullWindow().get_amplitude(self.input_data)
        if amplitude_threshold_abs is not None:
            if self.verbose:
                print(&#39;Pre-filtering data with absolute threshold {}.&#39;.format(amplitude_threshold_abs))
            self.input_data = self.input_data[amplitudes &gt; amplitude_threshold_abs]
        elif amplitude_threshold_std is not None:
            if self.verbose:
                print(&#39;Pre-filtering data with threshold at {} baseline &#39;
                      &#39;standard deviations.&#39;.format(amplitude_threshold_std))
            thresholds = amplitude_threshold_std * self.input_data_std
            self.input_data = self.input_data[amplitudes &gt; thresholds]
            self.input_data_std = self.input_data_std[amplitudes &gt; thresholds]

    @staticmethod
    def convert_to_amplitude(input_data: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;Convert input_data ADC values to baseline-subtracted and sign reversed values
        (i.e. equivalent to amplitude definition).

        Args:
            input_data: Array with ADC data of shape (number of waveforms, time bins per waveform).

        Returns:
            output: Baseline-subtracted and sign reversed input values.
        &#34;&#34;&#34;
        baselines = FullWindow().get_baseline(input_data)
        output = - np.subtract(input_data.T, baselines).T

        return output

    def find_ap(self, height: float, distance: float = 6, prominence_std: float = 8):
        &#34;&#34;&#34;Find waveforms with at least two pulses using `scipy.signal.find_peaks`.
        The `df` attribute will be expanded by the following columns:

        - `idx`: running index to indicate waveforms with more than two found pulses
        - `input_data_converted`: baseline-subtracted and sign reversed afterpulse candidate waveform values
        - `input_data_std`: baseline standard deviation
        - `p0_position`: index position of first found pulse
        - `p1_position`: index position of afterpulse candidate

        For large datasets, the input_data attribute gets overwritten to save memory, as it won&#39;t be used
        anymore thereafter, and it is still implicitly available through `df.input_data_converted`.

        Args:
            height: Required height of peaks. Fixed threshold above noise, deduced from amplitude spectrum.
            distance: Required minimal horizontal distance (&gt;= 1) in samples between neighbouring peaks.
                Smaller peaks are removed first until the condition is fulfilled for all remaining peaks.
            prominence_std: Required prominence of peaks in units of baseline standard deviations.
        &#34;&#34;&#34;
        if self.verbose:
            print(&#39;Finding waveforms with afterpulse candidates.&#39;)
        input_data_converted = self.convert_to_amplitude(self.input_data)
        prominence = prominence_std * FullWindow().get_baseline_std(self.input_data)

        # Overwrite self.input_data for large data sets to save memory, as it won&#39;t be used anymore hereafter,
        # and it is still implicitly available through `df.input_data_converted`.
        if self.input_data.shape[0] &gt; 5e5:
            warnings.warn(&#39;Overwriting input_data attribute to save memory, &#39;
                          &#39;use df.input_data_converted attribute instead.&#39;)
            self.input_data = np.array([&#39;Removed to save memory, use df.input_data_converted attribute instead.&#39;])

        idx = 0
        for i, el in tqdm(enumerate(input_data_converted)):  # TODO: try to vectorize
            peak_positions, _ = find_peaks(el,
                                           height=height,
                                           prominence=prominence[i],
                                           distance=distance)
            if peak_positions.shape[0] &gt; 1:
                p0_position = peak_positions[0]
                input_data_std = self.input_data_std[i]
                for p1_position in peak_positions[1:]:
                    df_add = pd.DataFrame({&#39;idx&#39;: [idx],
                                           &#39;input_data_converted&#39;: [el.tolist()],
                                           &#39;input_data_std&#39;: input_data_std,
                                           &#39;p0_position&#39;: [p0_position],
                                           &#39;p1_position&#39;: [p1_position]})
                    self.df = pd.concat([self.df, df_add])
                idx += 1
        self.df.reset_index(drop=True, inplace=True)

    def constrain_main_peak(self, trim: bool = True):
        &#34;&#34;&#34;Identify whether the first found pulse is a viable candidate for the main pulse
        (e.g. the LED induced signal) based on its timing compared to the other main pulse candidates.

        Args:
            trim: If `True`, remove events where the first found pulse is not a viable candidate for the main pulse and
                hence the afterpulse event may be misidentified. If `False` only add column `valid_main_pulse` to `df`.
        &#34;&#34;&#34;
        # Define relevant percentiles
        lp = np.percentile(self.df[&#39;p0_position&#39;], (100 - 68.27) / 2)
        cp = np.percentile(self.df[&#39;p0_position&#39;], 50)
        up = np.percentile(self.df[&#39;p0_position&#39;], 100 - (100 - 68.27) / 2)
        sf = 5  # acceptable Gaussian standard deviations from median
        lt = cp - sf * (cp - lp)
        ut = cp + sf * (up - cp)

        # Apply main peak thresholds
        valid_main_pulse = (self.df[&#39;p0_position&#39;] &gt;= lt) &amp; (self.df[&#39;p0_position&#39;] &lt;= ut)
        if trim:
            if self.verbose:
                print(&#39;Constraining main peak.&#39;)
            self.df = self.df[valid_main_pulse]
            self.df.drop([&#39;valid_main_pulse&#39;], axis=1, errors=&#39;ignore&#39;, inplace=True)
        else:
            self.df[&#39;valid_main_pulse&#39;] = valid_main_pulse

    def get_ap_properties(self):
        &#34;&#34;&#34;Calculate properties of found main pulse and afterpulse candidates and add corresponding columns to `df`.

        - `t_diff_ns`: Temporal difference main pulse and afterpulse in ns.
        - `p0_amplitude`: Amplitude of the main pulse candidate (in ADC bins).
        - `p1_amplitude`: Amplitude of the afterpulse candidate (in ADC bins).
        - `p0_lower_bound`: Lower bound of main pulse candidate integration window.
        - `p0_upper_bound`: Upper bound of main pulse candidate integration window.
        - `p0_area`: Area of main pulse candidate.
        - `p1_lower_bound`: Lower bound of afterpulse candidate integration window.
        - `p1_upper_bound`: Upper bound of afterpulse candidate integration window.
        - `p1_area`: Area of afterpulse candidate.
        - `separable`: Boolean stating whether main pulse and afterpulse candidates are separable and not overlapping.
            Only if true, area and amplitude calculations are reliable.
        &#34;&#34;&#34;
        if self.verbose:
            print(&#39;Calculating peak properties.&#39;)
        # Temporal difference main pulse and afterpulse
        self.df[&#39;t_diff_ns&#39;] = (self.df[&#39;p1_position&#39;] - self.df[&#39;p0_position&#39;]) / (self.adc_f * 1e-9)

        # Amplitudes found pulses
        self.df[&#39;p0_amplitude&#39;] = np.array(self.df[&#39;input_data_converted&#39;].tolist())[np.arange(self.df.shape[0]),
                                                                                     np.array(self.df[&#39;p0_position&#39;])]
        self.df[&#39;p1_amplitude&#39;] = np.array(self.df[&#39;input_data_converted&#39;].tolist())[np.arange(self.df.shape[0]),
                                                                                     np.array(self.df[&#39;p1_position&#39;])]
        # Peak ranges and areas
        valley = np.zeros(self.df.shape[0])
        p0_lower_bound = np.zeros(self.df.shape[0], dtype=int)
        p0_upper_bound = np.zeros(self.df.shape[0], dtype=int)
        p0_area = np.zeros(self.df.shape[0])
        p1_lower_bound = np.zeros(self.df.shape[0], dtype=int)
        p1_upper_bound = np.zeros(self.df.shape[0], dtype=int)
        p1_area = np.zeros(self.df.shape[0])
        separable = np.zeros(self.df.shape[0], dtype=bool)

        for i, el in enumerate(self.df[&#39;input_data_converted&#39;]):
            # Position of the lowest value between identified main pulse and afterpulse candidates
            valley[i] = np.argmin(el[self.df[&#39;p0_position&#39;].iloc[i]:self.df[&#39;p1_position&#39;].iloc[i]]) + \
                        self.df[&#39;p0_position&#39;].iloc[i]

            # Lower window bound for main pulse candidate area estimation, take third last entry below
            # one sigma above baseline before main pulse candidate
            try:
                p0_lower_bound[i] = np.where(el[:self.df[&#39;p0_position&#39;].iloc[i]] &lt; self.input_data_std[i])[0][-3]
            except IndexError:
                p0_lower_bound[i] = 0  # unconstrained

            # Upper window bound for main pulse candidate area estimation, take third entry below
            # one sigma above baseline after main pulse candidate or &#39;valley&#39; value
            try:
                p0_upper_bound[i] = (np.where(el[self.df[&#39;p0_position&#39;].iloc[i]:] &lt; self.input_data_std[i])[0][2]) + \
                                    self.df[&#39;p0_position&#39;].iloc[i]
            except IndexError:
                p0_upper_bound[i] = valley[i]  # take &#39;valley&#39; value
            p0_upper_bound[i] = min(p0_upper_bound[i], valley[i])

            # Lower window bound for afterpulse candidate area estimation, take third last entry below
            # one sigma above baseline before afterpulse candidate or &#39;valley&#39; value
            try:
                p1_lower_bound[i] = np.where(el[:self.df[&#39;p1_position&#39;].iloc[i]] &lt; self.input_data_std[i])[0][-3]
            except IndexError:
                p1_lower_bound[i] = valley[i]  # take &#39;valley&#39; value
            p1_lower_bound[i] = max(p1_lower_bound[i], valley[i])

            # Upper window bound for afterpulse candidate area estimation, take third entry below
            # one sigma above baseline after afterpulse candidate
            try:
                p1_upper_bound[i] = (np.where(el[self.df[&#39;p1_position&#39;].iloc[i]:] &lt; self.input_data_std[i])[0][2]) + \
                                    self.df[&#39;p1_position&#39;].iloc[i]
            except IndexError:
                p1_upper_bound[i] = len(el) - 1  # unconstrained

            # Peak areas
            p0_area[i] = np.sum(el[p0_lower_bound[i]:p0_upper_bound[i] + 1])
            p1_area[i] = np.sum(el[p1_lower_bound[i]:p1_upper_bound[i] + 1])

            # Consider main pulse and afterpulse candidates separable if a minimum value between their respective
            # positions of at most 5% main pulse or afterpulse candidate height is reached.
            separable[i] = (el[int(valley[i])] &lt;= 0.05*max(self.df.iloc[i][&#39;p0_amplitude&#39;],
                                                           self.df.iloc[i][&#39;p1_amplitude&#39;]))

        self.df[&#39;p0_lower_bound&#39;] = p0_lower_bound
        self.df[&#39;p0_upper_bound&#39;] = p0_upper_bound
        self.df[&#39;p0_area&#39;] = p0_area
        self.df[&#39;p1_lower_bound&#39;] = p1_lower_bound
        self.df[&#39;p1_upper_bound&#39;] = p1_upper_bound
        self.df[&#39;p1_area&#39;] = p1_area
        self.df[&#39;separable&#39;] = separable

    def multi_ap(self):
        &#34;&#34;&#34;Find multi-afterpulse candidates that are merged in the area estimation.

        Split separable multi-afterpulse candidates in the same waveform and remove duplicate waveforms
        of non-separable, merged multi-afterpulse candidates to avoid double counting
        &#34;&#34;&#34;
        idx_multi_ap = [item for item, count in collections.Counter(self.df.idx.tolist()).items() if count &gt; 1]
        if self.verbose:
            print(&#39;Finding multi-afterpulse candidates that are merged in the area estimation.&#39;)
            print(&#39;Found total of {} multi-afterpulse candidate waveforms out of {} ({} distinct) general afterpulse &#39;
                  &#39;candidate waveforms.&#39;.format(len(idx_multi_ap), self.df.shape[0], len(np.unique(self.df.idx))))
        if len(idx_multi_ap) &gt; 0:
            n_rows = self.df.shape[0]
            # Entries to be modified, only alter values after all iterations
            mods = {&#39;index&#39;: [], &#39;param_name&#39;: [], &#39;param_val&#39;: []}
            duplicates = []
            for i, el in enumerate(self.df[&#39;input_data_converted&#39;]):
                # Check if following afterpulse candidate in same waveform
                if (i &lt; n_rows - 1) and (self.df[&#39;idx&#39;].iloc[i] == self.df[&#39;idx&#39;].iloc[i + 1]):
                    # Check if identified with same integration window
                    if (self.df[&#39;p1_lower_bound&#39;].iloc[i] == self.df[&#39;p1_lower_bound&#39;].iloc[i + 1]) and (
                            self.df[&#39;p1_upper_bound&#39;].iloc[i] == self.df[&#39;p1_upper_bound&#39;].iloc[i + 1]):
                        # Position of the lowest value between present and subsequent afterpulse candidate
                        valley = np.argmin(el[self.df[&#39;p1_position&#39;].iloc[i]:self.df[&#39;p1_position&#39;].iloc[i + 1]]) + \
                                 self.df[&#39;p1_position&#39;].iloc[i]
                        # Check if present and subsequent afterpulse candidate separable,
                        # i.e. valley at most 30% of both peaks
                        separable = (el[valley] &lt;= 0.3 * self.df[&#39;p1_amplitude&#39;].iloc[i]) and (
                                    el[valley] &lt;= 0.3 * self.df[&#39;p1_amplitude&#39;].iloc[i + 1])
                        if separable:
                            mods[&#39;index&#39;].append(self.df.index[i])
                            mods[&#39;param_name&#39;].append(&#39;p1_upper_bound&#39;)
                            mods[&#39;param_val&#39;].append(valley)
                # Check if previous afterpulse candidate in same waveform
                if (i &gt; 0) and (self.df[&#39;idx&#39;].iloc[i] == self.df[&#39;idx&#39;].iloc[i - 1]):
                    # Check if identified with same integration window
                    if (self.df[&#39;p1_lower_bound&#39;].iloc[i] == self.df[&#39;p1_lower_bound&#39;].iloc[i - 1]) and (
                            self.df[&#39;p1_upper_bound&#39;].iloc[i] == self.df[&#39;p1_upper_bound&#39;].iloc[i - 1]):
                        # Position of the lowest value between present and subsequent afterpulse candidate
                        valley = np.argmin(el[self.df[&#39;p1_position&#39;].iloc[i - 1]:self.df[&#39;p1_position&#39;].iloc[i]]) + \
                                 self.df[&#39;p1_position&#39;].iloc[i - 1]
                        # Check if present and subsequent afterpulse candidate separable,
                        # i.e. valley at most 30% of both peaks
                        separable = (el[valley] &lt;= 0.3 * self.df[&#39;p1_amplitude&#39;].iloc[i - 1]) and (
                                    el[valley] &lt;= 0.3 * self.df[&#39;p1_amplitude&#39;].iloc[i])
                        if separable:
                            mods[&#39;index&#39;].append(self.df.index[i])
                            mods[&#39;param_name&#39;].append(&#39;p1_lower_bound&#39;)
                            mods[&#39;param_val&#39;].append(valley)
                        else:
                            duplicates.append(self.df.index[i])

            # Modify integration bounds for separable multi-afterpulse candidates and update area estimate accordingly
            if len(mods[&#39;index&#39;]) &gt; 0:
                for i, ind in enumerate(mods[&#39;index&#39;]):
                    self.df.at[ind, mods[&#39;param_name&#39;][i]] = mods[&#39;param_val&#39;][i]
                    self.df.at[ind, &#39;p1_area&#39;] = np.sum(
                        (self.df.at[ind, &#39;input_data_converted&#39;])[self.df.at[ind, &#39;p1_lower_bound&#39;]:
                                                                  self.df.at[ind, &#39;p1_upper_bound&#39;] + 1])

            # Remove duplicate waveforms of non-separable, merged multi-afterpulse candidates to avoid double counting
            self.df.drop(index=duplicates, inplace=True)

            if self.verbose:
                print(
                    &#39;Found {} yet unsplit afterpulse candidates and removed {} duplicate waveforms of merged &#39;
                    &#39;multi-afterpulse candidates.&#39;.format(len(mods[&#39;index&#39;]), len(duplicates)))
        else:
            if self.verbose:
                print(&#39;No merged multi-afterpulse candidate waveforms found.&#39;)

    def ap_rate(self):
        &#34;&#34;&#34;Calculate afterpulse rates, normalized to the occupancy.

        - `n_ap`: Total number of identified afterpulses.
        - `n_ap_separable`: Total number of identified afterpulses separable from the main pulse.
        - `ap_fraction`: Fraction of waveforms with identified afterpulse(s).
        - `ap_fraction_unc`: Statistical uncertainty of the fraction of waveforms with identified afterpulse(s).
        - `ap_fraction_separable`: Fraction of waveforms with identified afterpulses separable from the main pulse.
        - `ap_fraction_separable_unc`: Statistical uncertainty of the fraction of waveforms with identified \
          afterpulses separable from the main pulse.
        - `ap_rate`: Afterpulse probability in units of afterpulses per PE.
        - `ap_rate_unc`: Uncertainty of the afterpulse probability in units of afterpulses per PE.
        - `ap_rate_separable`: Afterpulse probability in units of afterpulses (separable from the main pulse) per PE.
        - `ap_rate_separable_unc`: Uncertainty of the afterpulse probability in units of afterpulses \
          (separable from the main pulse) per PE.
        - `amp_thr_ap`: Lower amplitude threshold for afterpulse candidates.
        - `ap_rate_separable_above_thr`: Afterpulse probability in units of afterpulses (separable from the main pulse)
          per PE for afterpulse candidates with amplitudes above `amp_thr_ap`.
        - `ap_rate_separable_unc_above_thr`: Uncertainty of the afterpulse probability in units of afterpulses
          (separable from the main pulse) per PE for afterpulse candidates with amplitudes above `amp_thr_ap`.
        &#34;&#34;&#34;
        n_ap = self.df.shape[0]
        n_ap_separable = np.sum(self.df.separable)
        ap_fraction = n_ap / self.n_samples
        ap_fraction_unc = np.sqrt(n_ap) / self.n_samples
        ap_fraction_separable = n_ap_separable / self.n_samples
        ap_fraction_separable_unc = np.sqrt(n_ap_separable) / self.n_samples
        if self.occupancy is None:
            warnings.warn(&#39;No occupancy given, afterpulse rate will not be fully calculated.&#39;)
            ap_rate = None
            ap_rate_unc = None
            ap_rate_separable = None
            ap_rate_separable_unc = None
            ap_rate_separable_above_thr = None
            ap_rate_separable_unc_above_thr = None
        else:
            ap_rate = ap_fraction / self.occupancy
            ap_rate_separable = ap_fraction_separable / self.occupancy
            if self.occupancy_unc is None:
                warnings.warn(&#39;No occupancy uncertainty given, will assume negligible occupancy uncertainty &#39;
                              &#39;for afterpulse rate calculation.&#39;)
                ap_rate_unc = ap_fraction_unc / self.occupancy
                ap_rate_separable_unc = ap_fraction_separable_unc / self.occupancy
            else:
                ap_rate_unc = ap_rate * np.sqrt((ap_fraction_unc/ap_fraction)**2
                                                + (self.occupancy_unc/self.occupancy)**2)
                ap_rate_separable_unc = ap_rate_separable * np.sqrt((ap_fraction_separable_unc /
                                                                     ap_fraction_separable) ** 2
                                                                    + (self.occupancy_unc/self.occupancy) ** 2)
            if self.amp_thr_ap is None:
                warnings.warn(&#39;No lower amplitude threshold for afterpulse candidates provided.&#39;)
                ap_rate_separable_above_thr = None
                ap_rate_separable_unc_above_thr = None
            else:
                n_ap_separable_above_thr = np.sum(self.df.separable &amp; (self.df.p1_amplitude &gt;= self.amp_thr_ap))
                ap_fraction_separable_above_thr = n_ap_separable_above_thr / self.n_samples
                ap_fraction_separable_unc_above_thr = np.sqrt(n_ap_separable_above_thr) / self.n_samples
                ap_rate_separable_above_thr = ap_fraction_separable_above_thr / self.occupancy
                if self.occupancy_unc is None:
                    ap_rate_separable_unc_above_thr = None
                else:
                    ap_rate_separable_unc_above_thr = (ap_rate_separable_above_thr
                                                       * np.sqrt((ap_fraction_separable_unc_above_thr /
                                                                  ap_fraction_separable_above_thr) ** 2
                                                                 + (self.occupancy_unc / self.occupancy) ** 2))

        self.ap_rate_dict = {&#39;n_ap&#39;: n_ap, &#39;n_ap_separable&#39;: n_ap_separable,
                             &#39;ap_fraction&#39;: ap_fraction, &#39;ap_fraction_unc&#39;: ap_fraction_unc,
                             &#39;ap_fraction_separable&#39;: ap_fraction_separable,
                             &#39;ap_fraction_separable_unc&#39;: ap_fraction_separable_unc,
                             &#39;ap_rate&#39;: ap_rate, &#39;ap_rate_unc&#39;: ap_rate_unc,
                             &#39;ap_rate_separable&#39;: ap_rate_separable, &#39;ap_rate_separable_unc&#39;: ap_rate_separable_unc,
                             &#39;amp_thr_ap&#39;: self.amp_thr_ap, &#39;ap_rate_separable_above_thr&#39;: ap_rate_separable_above_thr,
                             &#39;ap_rate_separable_unc_above_thr&#39;: ap_rate_separable_unc_above_thr
                             }

    def compute(self, height: float, distance: float = 6, prominence_std: float = 8,
                constrain_main_peak: bool = True):
        &#34;&#34;&#34;Perform full afterpulse analysis.

        Args:
            height: Required height of peaks. Fixed threshold above noise, deduced from amplitude spectrum.
            distance: Required minimal horizontal distance (&gt;= 1) in samples between neighbouring peaks.
                Smaller peaks are removed first until the condition is fulfilled for all remaining peaks.
            prominence_std: Required prominence of peaks in units of baseline standard deviations.
            constrain_main_peak: Remove events where the first found pulse is not a viable candidate for
                the main pulse.
        &#34;&#34;&#34;
        self.find_ap(height=height, distance=distance, prominence_std=prominence_std)
        self.constrain_main_peak(trim=constrain_main_peak)
        self.get_ap_properties()
        self.multi_ap()
        self.ap_rate()</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="pmt_analysis.processing.afterpulses.AfterPulses.convert_to_amplitude"><code class="name flex">
<span>def <span class="ident">convert_to_amplitude</span></span>(<span>input_data: numpy.ndarray) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Convert input_data ADC values to baseline-subtracted and sign reversed values
(i.e. equivalent to amplitude definition).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input_data</code></strong></dt>
<dd>Array with ADC data of shape (number of waveforms, time bins per waveform).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>output</code></dt>
<dd>Baseline-subtracted and sign reversed input values.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def convert_to_amplitude(input_data: np.ndarray) -&gt; np.ndarray:
    &#34;&#34;&#34;Convert input_data ADC values to baseline-subtracted and sign reversed values
    (i.e. equivalent to amplitude definition).

    Args:
        input_data: Array with ADC data of shape (number of waveforms, time bins per waveform).

    Returns:
        output: Baseline-subtracted and sign reversed input values.
    &#34;&#34;&#34;
    baselines = FullWindow().get_baseline(input_data)
    output = - np.subtract(input_data.T, baselines).T

    return output</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pmt_analysis.processing.afterpulses.AfterPulses.ap_rate"><code class="name flex">
<span>def <span class="ident">ap_rate</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate afterpulse rates, normalized to the occupancy.</p>
<ul>
<li><code>n_ap</code>: Total number of identified afterpulses.</li>
<li><code>n_ap_separable</code>: Total number of identified afterpulses separable from the main pulse.</li>
<li><code>ap_fraction</code>: Fraction of waveforms with identified afterpulse(s).</li>
<li><code>ap_fraction_unc</code>: Statistical uncertainty of the fraction of waveforms with identified afterpulse(s).</li>
<li><code>ap_fraction_separable</code>: Fraction of waveforms with identified afterpulses separable from the main pulse.</li>
<li><code>ap_fraction_separable_unc</code>: Statistical uncertainty of the fraction of waveforms with identified
afterpulses separable from the main pulse.</li>
<li><code>ap_rate</code>: Afterpulse probability in units of afterpulses per PE.</li>
<li><code>ap_rate_unc</code>: Uncertainty of the afterpulse probability in units of afterpulses per PE.</li>
<li><code>ap_rate_separable</code>: Afterpulse probability in units of afterpulses (separable from the main pulse) per PE.</li>
<li><code>ap_rate_separable_unc</code>: Uncertainty of the afterpulse probability in units of afterpulses
(separable from the main pulse) per PE.</li>
<li><code>amp_thr_ap</code>: Lower amplitude threshold for afterpulse candidates.</li>
<li><code>ap_rate_separable_above_thr</code>: Afterpulse probability in units of afterpulses (separable from the main pulse)
per PE for afterpulse candidates with amplitudes above <code>amp_thr_ap</code>.</li>
<li><code>ap_rate_separable_unc_above_thr</code>: Uncertainty of the afterpulse probability in units of afterpulses
(separable from the main pulse) per PE for afterpulse candidates with amplitudes above <code>amp_thr_ap</code>.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ap_rate(self):
    &#34;&#34;&#34;Calculate afterpulse rates, normalized to the occupancy.

    - `n_ap`: Total number of identified afterpulses.
    - `n_ap_separable`: Total number of identified afterpulses separable from the main pulse.
    - `ap_fraction`: Fraction of waveforms with identified afterpulse(s).
    - `ap_fraction_unc`: Statistical uncertainty of the fraction of waveforms with identified afterpulse(s).
    - `ap_fraction_separable`: Fraction of waveforms with identified afterpulses separable from the main pulse.
    - `ap_fraction_separable_unc`: Statistical uncertainty of the fraction of waveforms with identified \
      afterpulses separable from the main pulse.
    - `ap_rate`: Afterpulse probability in units of afterpulses per PE.
    - `ap_rate_unc`: Uncertainty of the afterpulse probability in units of afterpulses per PE.
    - `ap_rate_separable`: Afterpulse probability in units of afterpulses (separable from the main pulse) per PE.
    - `ap_rate_separable_unc`: Uncertainty of the afterpulse probability in units of afterpulses \
      (separable from the main pulse) per PE.
    - `amp_thr_ap`: Lower amplitude threshold for afterpulse candidates.
    - `ap_rate_separable_above_thr`: Afterpulse probability in units of afterpulses (separable from the main pulse)
      per PE for afterpulse candidates with amplitudes above `amp_thr_ap`.
    - `ap_rate_separable_unc_above_thr`: Uncertainty of the afterpulse probability in units of afterpulses
      (separable from the main pulse) per PE for afterpulse candidates with amplitudes above `amp_thr_ap`.
    &#34;&#34;&#34;
    n_ap = self.df.shape[0]
    n_ap_separable = np.sum(self.df.separable)
    ap_fraction = n_ap / self.n_samples
    ap_fraction_unc = np.sqrt(n_ap) / self.n_samples
    ap_fraction_separable = n_ap_separable / self.n_samples
    ap_fraction_separable_unc = np.sqrt(n_ap_separable) / self.n_samples
    if self.occupancy is None:
        warnings.warn(&#39;No occupancy given, afterpulse rate will not be fully calculated.&#39;)
        ap_rate = None
        ap_rate_unc = None
        ap_rate_separable = None
        ap_rate_separable_unc = None
        ap_rate_separable_above_thr = None
        ap_rate_separable_unc_above_thr = None
    else:
        ap_rate = ap_fraction / self.occupancy
        ap_rate_separable = ap_fraction_separable / self.occupancy
        if self.occupancy_unc is None:
            warnings.warn(&#39;No occupancy uncertainty given, will assume negligible occupancy uncertainty &#39;
                          &#39;for afterpulse rate calculation.&#39;)
            ap_rate_unc = ap_fraction_unc / self.occupancy
            ap_rate_separable_unc = ap_fraction_separable_unc / self.occupancy
        else:
            ap_rate_unc = ap_rate * np.sqrt((ap_fraction_unc/ap_fraction)**2
                                            + (self.occupancy_unc/self.occupancy)**2)
            ap_rate_separable_unc = ap_rate_separable * np.sqrt((ap_fraction_separable_unc /
                                                                 ap_fraction_separable) ** 2
                                                                + (self.occupancy_unc/self.occupancy) ** 2)
        if self.amp_thr_ap is None:
            warnings.warn(&#39;No lower amplitude threshold for afterpulse candidates provided.&#39;)
            ap_rate_separable_above_thr = None
            ap_rate_separable_unc_above_thr = None
        else:
            n_ap_separable_above_thr = np.sum(self.df.separable &amp; (self.df.p1_amplitude &gt;= self.amp_thr_ap))
            ap_fraction_separable_above_thr = n_ap_separable_above_thr / self.n_samples
            ap_fraction_separable_unc_above_thr = np.sqrt(n_ap_separable_above_thr) / self.n_samples
            ap_rate_separable_above_thr = ap_fraction_separable_above_thr / self.occupancy
            if self.occupancy_unc is None:
                ap_rate_separable_unc_above_thr = None
            else:
                ap_rate_separable_unc_above_thr = (ap_rate_separable_above_thr
                                                   * np.sqrt((ap_fraction_separable_unc_above_thr /
                                                              ap_fraction_separable_above_thr) ** 2
                                                             + (self.occupancy_unc / self.occupancy) ** 2))

    self.ap_rate_dict = {&#39;n_ap&#39;: n_ap, &#39;n_ap_separable&#39;: n_ap_separable,
                         &#39;ap_fraction&#39;: ap_fraction, &#39;ap_fraction_unc&#39;: ap_fraction_unc,
                         &#39;ap_fraction_separable&#39;: ap_fraction_separable,
                         &#39;ap_fraction_separable_unc&#39;: ap_fraction_separable_unc,
                         &#39;ap_rate&#39;: ap_rate, &#39;ap_rate_unc&#39;: ap_rate_unc,
                         &#39;ap_rate_separable&#39;: ap_rate_separable, &#39;ap_rate_separable_unc&#39;: ap_rate_separable_unc,
                         &#39;amp_thr_ap&#39;: self.amp_thr_ap, &#39;ap_rate_separable_above_thr&#39;: ap_rate_separable_above_thr,
                         &#39;ap_rate_separable_unc_above_thr&#39;: ap_rate_separable_unc_above_thr
                         }</code></pre>
</details>
</dd>
<dt id="pmt_analysis.processing.afterpulses.AfterPulses.compute"><code class="name flex">
<span>def <span class="ident">compute</span></span>(<span>self, height: float, distance: float = 6, prominence_std: float = 8, constrain_main_peak: bool = True)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform full afterpulse analysis.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>height</code></strong></dt>
<dd>Required height of peaks. Fixed threshold above noise, deduced from amplitude spectrum.</dd>
<dt><strong><code>distance</code></strong></dt>
<dd>Required minimal horizontal distance (&gt;= 1) in samples between neighbouring peaks.
Smaller peaks are removed first until the condition is fulfilled for all remaining peaks.</dd>
<dt><strong><code>prominence_std</code></strong></dt>
<dd>Required prominence of peaks in units of baseline standard deviations.</dd>
<dt><strong><code>constrain_main_peak</code></strong></dt>
<dd>Remove events where the first found pulse is not a viable candidate for
the main pulse.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute(self, height: float, distance: float = 6, prominence_std: float = 8,
            constrain_main_peak: bool = True):
    &#34;&#34;&#34;Perform full afterpulse analysis.

    Args:
        height: Required height of peaks. Fixed threshold above noise, deduced from amplitude spectrum.
        distance: Required minimal horizontal distance (&gt;= 1) in samples between neighbouring peaks.
            Smaller peaks are removed first until the condition is fulfilled for all remaining peaks.
        prominence_std: Required prominence of peaks in units of baseline standard deviations.
        constrain_main_peak: Remove events where the first found pulse is not a viable candidate for
            the main pulse.
    &#34;&#34;&#34;
    self.find_ap(height=height, distance=distance, prominence_std=prominence_std)
    self.constrain_main_peak(trim=constrain_main_peak)
    self.get_ap_properties()
    self.multi_ap()
    self.ap_rate()</code></pre>
</details>
</dd>
<dt id="pmt_analysis.processing.afterpulses.AfterPulses.constrain_main_peak"><code class="name flex">
<span>def <span class="ident">constrain_main_peak</span></span>(<span>self, trim: bool = True)</span>
</code></dt>
<dd>
<div class="desc"><p>Identify whether the first found pulse is a viable candidate for the main pulse
(e.g. the LED induced signal) based on its timing compared to the other main pulse candidates.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>trim</code></strong></dt>
<dd>If <code>True</code>, remove events where the first found pulse is not a viable candidate for the main pulse and
hence the afterpulse event may be misidentified. If <code>False</code> only add column <code>valid_main_pulse</code> to <code>df</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def constrain_main_peak(self, trim: bool = True):
    &#34;&#34;&#34;Identify whether the first found pulse is a viable candidate for the main pulse
    (e.g. the LED induced signal) based on its timing compared to the other main pulse candidates.

    Args:
        trim: If `True`, remove events where the first found pulse is not a viable candidate for the main pulse and
            hence the afterpulse event may be misidentified. If `False` only add column `valid_main_pulse` to `df`.
    &#34;&#34;&#34;
    # Define relevant percentiles
    lp = np.percentile(self.df[&#39;p0_position&#39;], (100 - 68.27) / 2)
    cp = np.percentile(self.df[&#39;p0_position&#39;], 50)
    up = np.percentile(self.df[&#39;p0_position&#39;], 100 - (100 - 68.27) / 2)
    sf = 5  # acceptable Gaussian standard deviations from median
    lt = cp - sf * (cp - lp)
    ut = cp + sf * (up - cp)

    # Apply main peak thresholds
    valid_main_pulse = (self.df[&#39;p0_position&#39;] &gt;= lt) &amp; (self.df[&#39;p0_position&#39;] &lt;= ut)
    if trim:
        if self.verbose:
            print(&#39;Constraining main peak.&#39;)
        self.df = self.df[valid_main_pulse]
        self.df.drop([&#39;valid_main_pulse&#39;], axis=1, errors=&#39;ignore&#39;, inplace=True)
    else:
        self.df[&#39;valid_main_pulse&#39;] = valid_main_pulse</code></pre>
</details>
</dd>
<dt id="pmt_analysis.processing.afterpulses.AfterPulses.find_ap"><code class="name flex">
<span>def <span class="ident">find_ap</span></span>(<span>self, height: float, distance: float = 6, prominence_std: float = 8)</span>
</code></dt>
<dd>
<div class="desc"><p>Find waveforms with at least two pulses using <code>scipy.signal.find_peaks</code>.
The <code>df</code> attribute will be expanded by the following columns:</p>
<ul>
<li><code>idx</code>: running index to indicate waveforms with more than two found pulses</li>
<li><code>input_data_converted</code>: baseline-subtracted and sign reversed afterpulse candidate waveform values</li>
<li><code>input_data_std</code>: baseline standard deviation</li>
<li><code>p0_position</code>: index position of first found pulse</li>
<li><code>p1_position</code>: index position of afterpulse candidate</li>
</ul>
<p>For large datasets, the input_data attribute gets overwritten to save memory, as it won't be used
anymore thereafter, and it is still implicitly available through <code>df.input_data_converted</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>height</code></strong></dt>
<dd>Required height of peaks. Fixed threshold above noise, deduced from amplitude spectrum.</dd>
<dt><strong><code>distance</code></strong></dt>
<dd>Required minimal horizontal distance (&gt;= 1) in samples between neighbouring peaks.
Smaller peaks are removed first until the condition is fulfilled for all remaining peaks.</dd>
<dt><strong><code>prominence_std</code></strong></dt>
<dd>Required prominence of peaks in units of baseline standard deviations.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_ap(self, height: float, distance: float = 6, prominence_std: float = 8):
    &#34;&#34;&#34;Find waveforms with at least two pulses using `scipy.signal.find_peaks`.
    The `df` attribute will be expanded by the following columns:

    - `idx`: running index to indicate waveforms with more than two found pulses
    - `input_data_converted`: baseline-subtracted and sign reversed afterpulse candidate waveform values
    - `input_data_std`: baseline standard deviation
    - `p0_position`: index position of first found pulse
    - `p1_position`: index position of afterpulse candidate

    For large datasets, the input_data attribute gets overwritten to save memory, as it won&#39;t be used
    anymore thereafter, and it is still implicitly available through `df.input_data_converted`.

    Args:
        height: Required height of peaks. Fixed threshold above noise, deduced from amplitude spectrum.
        distance: Required minimal horizontal distance (&gt;= 1) in samples between neighbouring peaks.
            Smaller peaks are removed first until the condition is fulfilled for all remaining peaks.
        prominence_std: Required prominence of peaks in units of baseline standard deviations.
    &#34;&#34;&#34;
    if self.verbose:
        print(&#39;Finding waveforms with afterpulse candidates.&#39;)
    input_data_converted = self.convert_to_amplitude(self.input_data)
    prominence = prominence_std * FullWindow().get_baseline_std(self.input_data)

    # Overwrite self.input_data for large data sets to save memory, as it won&#39;t be used anymore hereafter,
    # and it is still implicitly available through `df.input_data_converted`.
    if self.input_data.shape[0] &gt; 5e5:
        warnings.warn(&#39;Overwriting input_data attribute to save memory, &#39;
                      &#39;use df.input_data_converted attribute instead.&#39;)
        self.input_data = np.array([&#39;Removed to save memory, use df.input_data_converted attribute instead.&#39;])

    idx = 0
    for i, el in tqdm(enumerate(input_data_converted)):  # TODO: try to vectorize
        peak_positions, _ = find_peaks(el,
                                       height=height,
                                       prominence=prominence[i],
                                       distance=distance)
        if peak_positions.shape[0] &gt; 1:
            p0_position = peak_positions[0]
            input_data_std = self.input_data_std[i]
            for p1_position in peak_positions[1:]:
                df_add = pd.DataFrame({&#39;idx&#39;: [idx],
                                       &#39;input_data_converted&#39;: [el.tolist()],
                                       &#39;input_data_std&#39;: input_data_std,
                                       &#39;p0_position&#39;: [p0_position],
                                       &#39;p1_position&#39;: [p1_position]})
                self.df = pd.concat([self.df, df_add])
            idx += 1
    self.df.reset_index(drop=True, inplace=True)</code></pre>
</details>
</dd>
<dt id="pmt_analysis.processing.afterpulses.AfterPulses.get_ap_properties"><code class="name flex">
<span>def <span class="ident">get_ap_properties</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate properties of found main pulse and afterpulse candidates and add corresponding columns to <code>df</code>.</p>
<ul>
<li><code>t_diff_ns</code>: Temporal difference main pulse and afterpulse in ns.</li>
<li><code>p0_amplitude</code>: Amplitude of the main pulse candidate (in ADC bins).</li>
<li><code>p1_amplitude</code>: Amplitude of the afterpulse candidate (in ADC bins).</li>
<li><code>p0_lower_bound</code>: Lower bound of main pulse candidate integration window.</li>
<li><code>p0_upper_bound</code>: Upper bound of main pulse candidate integration window.</li>
<li><code>p0_area</code>: Area of main pulse candidate.</li>
<li><code>p1_lower_bound</code>: Lower bound of afterpulse candidate integration window.</li>
<li><code>p1_upper_bound</code>: Upper bound of afterpulse candidate integration window.</li>
<li><code>p1_area</code>: Area of afterpulse candidate.</li>
<li><code>separable</code>: Boolean stating whether main pulse and afterpulse candidates are separable and not overlapping.
Only if true, area and amplitude calculations are reliable.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_ap_properties(self):
    &#34;&#34;&#34;Calculate properties of found main pulse and afterpulse candidates and add corresponding columns to `df`.

    - `t_diff_ns`: Temporal difference main pulse and afterpulse in ns.
    - `p0_amplitude`: Amplitude of the main pulse candidate (in ADC bins).
    - `p1_amplitude`: Amplitude of the afterpulse candidate (in ADC bins).
    - `p0_lower_bound`: Lower bound of main pulse candidate integration window.
    - `p0_upper_bound`: Upper bound of main pulse candidate integration window.
    - `p0_area`: Area of main pulse candidate.
    - `p1_lower_bound`: Lower bound of afterpulse candidate integration window.
    - `p1_upper_bound`: Upper bound of afterpulse candidate integration window.
    - `p1_area`: Area of afterpulse candidate.
    - `separable`: Boolean stating whether main pulse and afterpulse candidates are separable and not overlapping.
        Only if true, area and amplitude calculations are reliable.
    &#34;&#34;&#34;
    if self.verbose:
        print(&#39;Calculating peak properties.&#39;)
    # Temporal difference main pulse and afterpulse
    self.df[&#39;t_diff_ns&#39;] = (self.df[&#39;p1_position&#39;] - self.df[&#39;p0_position&#39;]) / (self.adc_f * 1e-9)

    # Amplitudes found pulses
    self.df[&#39;p0_amplitude&#39;] = np.array(self.df[&#39;input_data_converted&#39;].tolist())[np.arange(self.df.shape[0]),
                                                                                 np.array(self.df[&#39;p0_position&#39;])]
    self.df[&#39;p1_amplitude&#39;] = np.array(self.df[&#39;input_data_converted&#39;].tolist())[np.arange(self.df.shape[0]),
                                                                                 np.array(self.df[&#39;p1_position&#39;])]
    # Peak ranges and areas
    valley = np.zeros(self.df.shape[0])
    p0_lower_bound = np.zeros(self.df.shape[0], dtype=int)
    p0_upper_bound = np.zeros(self.df.shape[0], dtype=int)
    p0_area = np.zeros(self.df.shape[0])
    p1_lower_bound = np.zeros(self.df.shape[0], dtype=int)
    p1_upper_bound = np.zeros(self.df.shape[0], dtype=int)
    p1_area = np.zeros(self.df.shape[0])
    separable = np.zeros(self.df.shape[0], dtype=bool)

    for i, el in enumerate(self.df[&#39;input_data_converted&#39;]):
        # Position of the lowest value between identified main pulse and afterpulse candidates
        valley[i] = np.argmin(el[self.df[&#39;p0_position&#39;].iloc[i]:self.df[&#39;p1_position&#39;].iloc[i]]) + \
                    self.df[&#39;p0_position&#39;].iloc[i]

        # Lower window bound for main pulse candidate area estimation, take third last entry below
        # one sigma above baseline before main pulse candidate
        try:
            p0_lower_bound[i] = np.where(el[:self.df[&#39;p0_position&#39;].iloc[i]] &lt; self.input_data_std[i])[0][-3]
        except IndexError:
            p0_lower_bound[i] = 0  # unconstrained

        # Upper window bound for main pulse candidate area estimation, take third entry below
        # one sigma above baseline after main pulse candidate or &#39;valley&#39; value
        try:
            p0_upper_bound[i] = (np.where(el[self.df[&#39;p0_position&#39;].iloc[i]:] &lt; self.input_data_std[i])[0][2]) + \
                                self.df[&#39;p0_position&#39;].iloc[i]
        except IndexError:
            p0_upper_bound[i] = valley[i]  # take &#39;valley&#39; value
        p0_upper_bound[i] = min(p0_upper_bound[i], valley[i])

        # Lower window bound for afterpulse candidate area estimation, take third last entry below
        # one sigma above baseline before afterpulse candidate or &#39;valley&#39; value
        try:
            p1_lower_bound[i] = np.where(el[:self.df[&#39;p1_position&#39;].iloc[i]] &lt; self.input_data_std[i])[0][-3]
        except IndexError:
            p1_lower_bound[i] = valley[i]  # take &#39;valley&#39; value
        p1_lower_bound[i] = max(p1_lower_bound[i], valley[i])

        # Upper window bound for afterpulse candidate area estimation, take third entry below
        # one sigma above baseline after afterpulse candidate
        try:
            p1_upper_bound[i] = (np.where(el[self.df[&#39;p1_position&#39;].iloc[i]:] &lt; self.input_data_std[i])[0][2]) + \
                                self.df[&#39;p1_position&#39;].iloc[i]
        except IndexError:
            p1_upper_bound[i] = len(el) - 1  # unconstrained

        # Peak areas
        p0_area[i] = np.sum(el[p0_lower_bound[i]:p0_upper_bound[i] + 1])
        p1_area[i] = np.sum(el[p1_lower_bound[i]:p1_upper_bound[i] + 1])

        # Consider main pulse and afterpulse candidates separable if a minimum value between their respective
        # positions of at most 5% main pulse or afterpulse candidate height is reached.
        separable[i] = (el[int(valley[i])] &lt;= 0.05*max(self.df.iloc[i][&#39;p0_amplitude&#39;],
                                                       self.df.iloc[i][&#39;p1_amplitude&#39;]))

    self.df[&#39;p0_lower_bound&#39;] = p0_lower_bound
    self.df[&#39;p0_upper_bound&#39;] = p0_upper_bound
    self.df[&#39;p0_area&#39;] = p0_area
    self.df[&#39;p1_lower_bound&#39;] = p1_lower_bound
    self.df[&#39;p1_upper_bound&#39;] = p1_upper_bound
    self.df[&#39;p1_area&#39;] = p1_area
    self.df[&#39;separable&#39;] = separable</code></pre>
</details>
</dd>
<dt id="pmt_analysis.processing.afterpulses.AfterPulses.multi_ap"><code class="name flex">
<span>def <span class="ident">multi_ap</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Find multi-afterpulse candidates that are merged in the area estimation.</p>
<p>Split separable multi-afterpulse candidates in the same waveform and remove duplicate waveforms
of non-separable, merged multi-afterpulse candidates to avoid double counting</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def multi_ap(self):
    &#34;&#34;&#34;Find multi-afterpulse candidates that are merged in the area estimation.

    Split separable multi-afterpulse candidates in the same waveform and remove duplicate waveforms
    of non-separable, merged multi-afterpulse candidates to avoid double counting
    &#34;&#34;&#34;
    idx_multi_ap = [item for item, count in collections.Counter(self.df.idx.tolist()).items() if count &gt; 1]
    if self.verbose:
        print(&#39;Finding multi-afterpulse candidates that are merged in the area estimation.&#39;)
        print(&#39;Found total of {} multi-afterpulse candidate waveforms out of {} ({} distinct) general afterpulse &#39;
              &#39;candidate waveforms.&#39;.format(len(idx_multi_ap), self.df.shape[0], len(np.unique(self.df.idx))))
    if len(idx_multi_ap) &gt; 0:
        n_rows = self.df.shape[0]
        # Entries to be modified, only alter values after all iterations
        mods = {&#39;index&#39;: [], &#39;param_name&#39;: [], &#39;param_val&#39;: []}
        duplicates = []
        for i, el in enumerate(self.df[&#39;input_data_converted&#39;]):
            # Check if following afterpulse candidate in same waveform
            if (i &lt; n_rows - 1) and (self.df[&#39;idx&#39;].iloc[i] == self.df[&#39;idx&#39;].iloc[i + 1]):
                # Check if identified with same integration window
                if (self.df[&#39;p1_lower_bound&#39;].iloc[i] == self.df[&#39;p1_lower_bound&#39;].iloc[i + 1]) and (
                        self.df[&#39;p1_upper_bound&#39;].iloc[i] == self.df[&#39;p1_upper_bound&#39;].iloc[i + 1]):
                    # Position of the lowest value between present and subsequent afterpulse candidate
                    valley = np.argmin(el[self.df[&#39;p1_position&#39;].iloc[i]:self.df[&#39;p1_position&#39;].iloc[i + 1]]) + \
                             self.df[&#39;p1_position&#39;].iloc[i]
                    # Check if present and subsequent afterpulse candidate separable,
                    # i.e. valley at most 30% of both peaks
                    separable = (el[valley] &lt;= 0.3 * self.df[&#39;p1_amplitude&#39;].iloc[i]) and (
                                el[valley] &lt;= 0.3 * self.df[&#39;p1_amplitude&#39;].iloc[i + 1])
                    if separable:
                        mods[&#39;index&#39;].append(self.df.index[i])
                        mods[&#39;param_name&#39;].append(&#39;p1_upper_bound&#39;)
                        mods[&#39;param_val&#39;].append(valley)
            # Check if previous afterpulse candidate in same waveform
            if (i &gt; 0) and (self.df[&#39;idx&#39;].iloc[i] == self.df[&#39;idx&#39;].iloc[i - 1]):
                # Check if identified with same integration window
                if (self.df[&#39;p1_lower_bound&#39;].iloc[i] == self.df[&#39;p1_lower_bound&#39;].iloc[i - 1]) and (
                        self.df[&#39;p1_upper_bound&#39;].iloc[i] == self.df[&#39;p1_upper_bound&#39;].iloc[i - 1]):
                    # Position of the lowest value between present and subsequent afterpulse candidate
                    valley = np.argmin(el[self.df[&#39;p1_position&#39;].iloc[i - 1]:self.df[&#39;p1_position&#39;].iloc[i]]) + \
                             self.df[&#39;p1_position&#39;].iloc[i - 1]
                    # Check if present and subsequent afterpulse candidate separable,
                    # i.e. valley at most 30% of both peaks
                    separable = (el[valley] &lt;= 0.3 * self.df[&#39;p1_amplitude&#39;].iloc[i - 1]) and (
                                el[valley] &lt;= 0.3 * self.df[&#39;p1_amplitude&#39;].iloc[i])
                    if separable:
                        mods[&#39;index&#39;].append(self.df.index[i])
                        mods[&#39;param_name&#39;].append(&#39;p1_lower_bound&#39;)
                        mods[&#39;param_val&#39;].append(valley)
                    else:
                        duplicates.append(self.df.index[i])

        # Modify integration bounds for separable multi-afterpulse candidates and update area estimate accordingly
        if len(mods[&#39;index&#39;]) &gt; 0:
            for i, ind in enumerate(mods[&#39;index&#39;]):
                self.df.at[ind, mods[&#39;param_name&#39;][i]] = mods[&#39;param_val&#39;][i]
                self.df.at[ind, &#39;p1_area&#39;] = np.sum(
                    (self.df.at[ind, &#39;input_data_converted&#39;])[self.df.at[ind, &#39;p1_lower_bound&#39;]:
                                                              self.df.at[ind, &#39;p1_upper_bound&#39;] + 1])

        # Remove duplicate waveforms of non-separable, merged multi-afterpulse candidates to avoid double counting
        self.df.drop(index=duplicates, inplace=True)

        if self.verbose:
            print(
                &#39;Found {} yet unsplit afterpulse candidates and removed {} duplicate waveforms of merged &#39;
                &#39;multi-afterpulse candidates.&#39;.format(len(mods[&#39;index&#39;]), len(duplicates)))
    else:
        if self.verbose:
            print(&#39;No merged multi-afterpulse candidate waveforms found.&#39;)</code></pre>
</details>
</dd>
<dt id="pmt_analysis.processing.afterpulses.AfterPulses.pre_filter"><code class="name flex">
<span>def <span class="ident">pre_filter</span></span>(<span>self, amplitude_threshold_abs: Optional[float] = None, amplitude_threshold_std: Optional[float] = 3)</span>
</code></dt>
<dd>
<div class="desc"><p>Method to exclude waveforms that do not contain any entries above an amplitude threshold,
i.e. no main pulse or afterpulse of a certain minimum size, in order to make further processing
more efficient.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>amplitude_threshold_abs</code></strong></dt>
<dd>Absolute amplitude threshold. Default: None (disabled).</dd>
<dt><strong><code>amplitude_threshold_std</code></strong></dt>
<dd>Amplitude threshold in units of baseline standard deviations.
Ensure that the signal-to-noise ratio is sufficient for the selected value. Default: 3.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pre_filter(self, amplitude_threshold_abs: Optional[float] = None,
               amplitude_threshold_std: Optional[float] = 3):
    &#34;&#34;&#34;Method to exclude waveforms that do not contain any entries above an amplitude threshold,
    i.e. no main pulse or afterpulse of a certain minimum size, in order to make further processing
    more efficient.

    Args:
        amplitude_threshold_abs: Absolute amplitude threshold. Default: None (disabled).
        amplitude_threshold_std: Amplitude threshold in units of baseline standard deviations.
            Ensure that the signal-to-noise ratio is sufficient for the selected value. Default: 3.
    &#34;&#34;&#34;
    if (amplitude_threshold_abs is not None) and (amplitude_threshold_std is not None):
        raise ValueError(&#39;Either amplitude_threshold_abs or amplitude_threshold_std must be None &#39;
                         &#39;to be disabled, using both options is not permitted.&#39;)
    elif (amplitude_threshold_abs is None) and (amplitude_threshold_std is None):
        raise ValueError(&#39;Either amplitude_threshold_abs or amplitude_threshold_std must have &#39;
                         &#39;a finite value.&#39;)
    amplitudes = FullWindow().get_amplitude(self.input_data)
    if amplitude_threshold_abs is not None:
        if self.verbose:
            print(&#39;Pre-filtering data with absolute threshold {}.&#39;.format(amplitude_threshold_abs))
        self.input_data = self.input_data[amplitudes &gt; amplitude_threshold_abs]
    elif amplitude_threshold_std is not None:
        if self.verbose:
            print(&#39;Pre-filtering data with threshold at {} baseline &#39;
                  &#39;standard deviations.&#39;.format(amplitude_threshold_std))
        thresholds = amplitude_threshold_std * self.input_data_std
        self.input_data = self.input_data[amplitudes &gt; thresholds]
        self.input_data_std = self.input_data_std[amplitudes &gt; thresholds]</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pmt_analysis.processing" href="index.html">pmt_analysis.processing</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pmt_analysis.processing.afterpulses.AfterPulses" href="#pmt_analysis.processing.afterpulses.AfterPulses">AfterPulses</a></code></h4>
<ul class="">
<li><code><a title="pmt_analysis.processing.afterpulses.AfterPulses.ap_rate" href="#pmt_analysis.processing.afterpulses.AfterPulses.ap_rate">ap_rate</a></code></li>
<li><code><a title="pmt_analysis.processing.afterpulses.AfterPulses.compute" href="#pmt_analysis.processing.afterpulses.AfterPulses.compute">compute</a></code></li>
<li><code><a title="pmt_analysis.processing.afterpulses.AfterPulses.constrain_main_peak" href="#pmt_analysis.processing.afterpulses.AfterPulses.constrain_main_peak">constrain_main_peak</a></code></li>
<li><code><a title="pmt_analysis.processing.afterpulses.AfterPulses.convert_to_amplitude" href="#pmt_analysis.processing.afterpulses.AfterPulses.convert_to_amplitude">convert_to_amplitude</a></code></li>
<li><code><a title="pmt_analysis.processing.afterpulses.AfterPulses.find_ap" href="#pmt_analysis.processing.afterpulses.AfterPulses.find_ap">find_ap</a></code></li>
<li><code><a title="pmt_analysis.processing.afterpulses.AfterPulses.get_ap_properties" href="#pmt_analysis.processing.afterpulses.AfterPulses.get_ap_properties">get_ap_properties</a></code></li>
<li><code><a title="pmt_analysis.processing.afterpulses.AfterPulses.multi_ap" href="#pmt_analysis.processing.afterpulses.AfterPulses.multi_ap">multi_ap</a></code></li>
<li><code><a title="pmt_analysis.processing.afterpulses.AfterPulses.pre_filter" href="#pmt_analysis.processing.afterpulses.AfterPulses.pre_filter">pre_filter</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>